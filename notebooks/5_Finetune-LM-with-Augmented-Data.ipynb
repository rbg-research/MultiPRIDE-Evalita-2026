{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d25684-e586-487d-98b1-238b28f88468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All random seeds set to 42\n",
      "training files: ['train_es.csv', 'train_en.csv', 'train_it.csv']\n",
      "Total training samples: 2988\n",
      "================================================================================\n",
      "CLASS DISTRIBUTION\n",
      "================================================================================\n",
      "\n",
      "Overall:\n",
      "  Class 0 (NOT_RECLAMATORY): 2560 (85.7%)\n",
      "  Class 1 (RECLAMATORY): 428 (14.3%)\n",
      "  Total: 2988\n",
      "\n",
      "Per Language:\n",
      "  EN: Class 0=938, Class 1=88, Total=1026\n",
      "  ES: Class 0=743, Class 1=133, Total=876\n",
      "  IT: Class 0=879, Class 1=207, Total=1086\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "from src.baseline.baseline import train_df, figures_root\n",
    "from src.finetune.finetuner import main\n",
    "from src.baseline.utils import calculate_class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acbe48fa-4751-4a12-92bd-8337b71f51b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2988, 5) (5976, 8)\n"
     ]
    }
   ],
   "source": [
    "original_data = train_df\n",
    "augmented_data = pd.read_csv(\"../data/augmented_multilingual_tweets.csv\")\n",
    "print(original_data.shape, augmented_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27231170-0d78-446d-aa0e-23dea9c8d9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8964, 5)\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.concat([original_data, augmented_data[list(original_data.columns)]], ignore_index=True)\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd97a2a-12b3-4a25-a8c0-045f562b7895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLASS DISTRIBUTION\n",
      "================================================================================\n",
      "\n",
      "Overall:\n",
      "  Class 0 (NOT_RECLAMATORY): 7680 (85.7%)\n",
      "  Class 1 (RECLAMATORY): 1284 (14.3%)\n",
      "  Total: 8964\n",
      "\n",
      "Per Language:\n",
      "  EN: Class 0=2560, Class 1=428, Total=2988\n",
      "  ES: Class 0=2560, Class 1=428, Total=2988\n",
      "  IT: Class 0=2560, Class 1=428, Total=2988\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calculate_class_distribution(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611a2e02-03da-4580-8e39-1c90af03de75",
   "metadata": {},
   "source": [
    "# Fine-Tuning on Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f0123e-cffa-4119-be97-d6476b7a91d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training would be start on the device: cuda\n",
      "Training would be start on the device: cuda\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration for fine-tuning\"\"\"\n",
    "\n",
    "    # Model configuration\n",
    "    MODEL_NAME = \"cardiffnlp/twitter-xlm-roberta-base\"  # Base model\n",
    "    NUM_LABELS = 2  # Binary classification\n",
    "    MAX_LENGTH = 128  # Maximum sequence length\n",
    "    NUM_FROZEN_LAYERS = 3  # Number of initial layers to freeze (0 = only train classification head)\n",
    "\n",
    "    # Training configuration\n",
    "    LEARNING_RATE = 2e-5\n",
    "    WEIGHT_DECAY = 0.01 \n",
    "    NUM_EPOCHS = 10\n",
    "    BATCH_SIZE = 8\n",
    "    GRADIENT_ACCUMULATION_STEPS = 2\n",
    "    WARMUP_RATIO = 0.15  # Warmup as % of total steps\n",
    "\n",
    "    # Early stopping\n",
    "    PATIENCE = 3\n",
    "    EVAL_STRATEGY = \"epoch\"  # Evaluate at end of each epoch\n",
    "\n",
    "    # Cross-validation\n",
    "    N_SPLITS = 5\n",
    "    TRAIN_RATIO = 0.8  # 80% for training from each fold\n",
    "    VAL_RATIO = 0.2  # 20% for validation from each fold\n",
    "\n",
    "    # Dynamic undersampling\n",
    "    DYNAMIC_UNDERSAMPLE = False  # Balance classes per epoch\n",
    "\n",
    "    # Model saving\n",
    "    MAX_MODELS_TO_SAVE = 2\n",
    "    OUTPUT_DIR = \"../fine_tuned_models\"\n",
    "    RESULTS_DIR = \"../results/roberta-fine-tune/original_and_augumented/\"\n",
    "\n",
    "    # Device\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training would be start on the device: {DEVICE}\")\n",
    "\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration for fine-tuning\"\"\"\n",
    "\n",
    "    # Model configuration\n",
    "    MODEL_NAME = \"cardiffnlp/twitter-xlm-roberta-base\"  # Base model\n",
    "    NUM_LABELS = 2  # Binary classification\n",
    "    MAX_LENGTH = 128  # Maximum sequence length\n",
    "    NUM_FROZEN_LAYERS = 3  # Number of initial layers to freeze (0 = only train classification head)\n",
    "\n",
    "    # Training configuration\n",
    "    LEARNING_RATE = 2e-5\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    NUM_EPOCHS = 10\n",
    "    BATCH_SIZE = 8\n",
    "    GRADIENT_ACCUMULATION_STEPS = 2\n",
    "    WARMUP_RATIO = 0.1  # Warmup as % of total steps\n",
    "\n",
    "    # Early stopping\n",
    "    PATIENCE = 3\n",
    "    EVAL_STRATEGY = \"epoch\"  # Evaluate at end of each epoch\n",
    "\n",
    "    # Cross-validation\n",
    "    N_SPLITS = 5\n",
    "    TRAIN_RATIO = 0.8  # 80% for training from each fold\n",
    "    VAL_RATIO = 0.2  # 20% for validation from each fold\n",
    "\n",
    "    # Dynamic undersampling\n",
    "    DYNAMIC_UNDERSAMPLE = False  # Balance classes per epoch\n",
    "\n",
    "    # Model saving\n",
    "    MAX_MODELS_TO_SAVE = 2\n",
    "    OUTPUT_DIR = \"../fine_tuned_models\"\n",
    "    RESULTS_DIR = \"../results/roberta-fine-tune/original_and_augumented/\"\n",
    "\n",
    "    # Device\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training would be start on the device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc4bd487-c125-4c65-a2af-4e1c3cf124a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 10:10:58,497 - INFO - ================================================================================\n",
      "2025-11-13 10:10:58,497 - INFO - Starting Fine-tuning Pipeline\n",
      "2025-11-13 10:10:58,497 - INFO - ================================================================================\n",
      "2025-11-13 10:10:58,508 - INFO - Fold 0: Train=5736, Val=1435\n",
      "2025-11-13 10:10:58,508 - INFO -   Train label dist: {0: 4914, 1: 822}\n",
      "2025-11-13 10:10:58,508 - INFO -   Train lang dist: {'en': 1912, 'es': 1912, 'it': 1912}\n",
      "2025-11-13 10:10:58,513 - INFO - Fold 1: Train=5736, Val=1435\n",
      "2025-11-13 10:10:58,514 - INFO -   Train label dist: {0: 4915, 1: 821}\n",
      "2025-11-13 10:10:58,514 - INFO -   Train lang dist: {'es': 1912, 'it': 1912, 'en': 1912}\n",
      "2025-11-13 10:10:58,520 - INFO - Fold 2: Train=5736, Val=1435\n",
      "2025-11-13 10:10:58,520 - INFO -   Train label dist: {0: 4915, 1: 821}\n",
      "2025-11-13 10:10:58,520 - INFO -   Train lang dist: {'es': 1912, 'en': 1912, 'it': 1912}\n",
      "2025-11-13 10:10:58,525 - INFO - Fold 3: Train=5736, Val=1435\n",
      "2025-11-13 10:10:58,526 - INFO -   Train label dist: {0: 4916, 1: 820}\n",
      "2025-11-13 10:10:58,526 - INFO -   Train lang dist: {'es': 1912, 'en': 1912, 'it': 1912}\n",
      "2025-11-13 10:10:58,531 - INFO - Fold 4: Train=5737, Val=1435\n",
      "2025-11-13 10:10:58,532 - INFO -   Train label dist: {0: 4916, 1: 821}\n",
      "2025-11-13 10:10:58,532 - INFO -   Train lang dist: {'it': 1913, 'es': 1912, 'en': 1912}\n",
      "2025-11-13 10:10:58,533 - INFO - \n",
      "================================================================================\n",
      "2025-11-13 10:10:58,533 - INFO - Fold 1/5\n",
      "2025-11-13 10:10:58,533 - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 0:\n",
      "  Train: 822 positive samples\n",
      "  Val:   205 positive samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-11-13 10:11:02,102 - INFO - Froze: Embeddings + First 3 Encoder Layers\n",
      "2025-11-13 10:11:02,103 - INFO - Trainable: Classification Head + Remaining Encoder Layers\n",
      "2025-11-13 10:11:02,104 - INFO - Trainable parameters: 64,382,978 / 278,045,186 (23.16%)\n",
      "2025-11-13 10:11:02,105 - INFO - Label weights: {0: 0.5836385836385837, 1: 3.489051094890511}\n",
      "2025-11-13 10:11:02,105 - INFO - Language weights: {'en': 1.0, 'es': 1.0, 'it': 1.0}\n",
      "2025-11-13 10:11:02,105 - INFO - Pos weight (for BCE): 5.9781\n",
      "2025-11-13 10:11:02,106 - INFO - \n",
      "Epoch 1/10\n",
      "Training: 100%|██████████| 717/717 [00:41<00:00, 17.26it/s, loss=0.135]\n",
      "Validating: 100%|██████████| 180/180 [00:03<00:00, 45.11it/s]\n",
      "2025-11-13 10:11:47,645 - INFO - Train Loss: 0.1344\n",
      "2025-11-13 10:11:47,645 - INFO - Val Loss: 0.1158\n",
      "2025-11-13 10:11:47,645 - INFO - Overall - Precision: 0.4286, Recall: 0.5000, F1: 0.4615\n",
      "2025-11-13 10:11:47,645 - INFO - en - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:11:47,645 - INFO - es - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:11:47,646 - INFO - it - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:11:48,622 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_0_f1_0.4615.pt (F1: 0.4615, Fold: 0, Epoch: 0)\n",
      "2025-11-13 10:11:48,623 - INFO - \n",
      "Epoch 2/10\n",
      "Training: 100%|██████████| 717/717 [00:41<00:00, 17.44it/s, loss=0.133]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 44.42it/s]\n",
      "2025-11-13 10:12:33,797 - INFO - Train Loss: 0.1326\n",
      "2025-11-13 10:12:33,797 - INFO - Val Loss: 0.1205\n",
      "2025-11-13 10:12:33,797 - INFO - Overall - Precision: 0.4286, Recall: 0.5000, F1: 0.4615\n",
      "2025-11-13 10:12:33,798 - INFO - en - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:12:33,798 - INFO - es - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:12:33,798 - INFO - it - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:12:33,798 - INFO - \n",
      "Epoch 3/10\n",
      "Training: 100%|██████████| 717/717 [00:33<00:00, 21.54it/s, loss=0.129]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.76it/s]\n",
      "2025-11-13 10:13:08,654 - INFO - Train Loss: 0.1287\n",
      "2025-11-13 10:13:08,654 - INFO - Val Loss: 0.1154\n",
      "2025-11-13 10:13:08,654 - INFO - Overall - Precision: 0.4286, Recall: 0.5000, F1: 0.4615\n",
      "2025-11-13 10:13:08,654 - INFO - en - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:13:08,654 - INFO - es - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:13:08,655 - INFO - it - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:13:08,655 - INFO - \n",
      "Epoch 4/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 36.11it/s, loss=0.124]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.36it/s]\n",
      "2025-11-13 10:13:30,081 - INFO - Train Loss: 0.1242\n",
      "2025-11-13 10:13:30,081 - INFO - Val Loss: 0.1096\n",
      "2025-11-13 10:13:30,081 - INFO - Overall - Precision: 0.4286, Recall: 0.5000, F1: 0.4615\n",
      "2025-11-13 10:13:30,081 - INFO - en - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:13:30,081 - INFO - es - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:13:30,082 - INFO - it - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:13:30,082 - INFO - Early stopping triggered at epoch 3 (patience: 3)\n",
      "2025-11-13 10:13:30,082 - INFO - \n",
      "================================================================================\n",
      "2025-11-13 10:13:30,082 - INFO - Fold 2/5\n",
      "2025-11-13 10:13:30,082 - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 1:\n",
      "  Train: 821 positive samples\n",
      "  Val:   206 positive samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-11-13 10:13:33,203 - INFO - Froze: Embeddings + First 3 Encoder Layers\n",
      "2025-11-13 10:13:33,203 - INFO - Trainable: Classification Head + Remaining Encoder Layers\n",
      "2025-11-13 10:13:33,204 - INFO - Trainable parameters: 64,382,978 / 278,045,186 (23.16%)\n",
      "2025-11-13 10:13:33,205 - INFO - Label weights: {0: 0.5835198372329603, 1: 3.4933008526187574}\n",
      "2025-11-13 10:13:33,205 - INFO - Language weights: {'es': 1.0, 'it': 1.0, 'en': 1.0}\n",
      "2025-11-13 10:13:33,205 - INFO - Pos weight (for BCE): 5.9866\n",
      "2025-11-13 10:13:33,207 - INFO - \n",
      "Epoch 1/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 36.12it/s, loss=0.134]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.89it/s]\n",
      "2025-11-13 10:13:54,630 - INFO - Train Loss: 0.1335\n",
      "2025-11-13 10:13:54,630 - INFO - Val Loss: 0.1146\n",
      "2025-11-13 10:13:54,630 - INFO - Overall - Precision: 0.4282, Recall: 0.5000, F1: 0.4613\n",
      "2025-11-13 10:13:54,630 - INFO - en - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:13:54,630 - INFO - es - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:13:54,630 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:13:55,556 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_0_f1_0.4613.pt (F1: 0.4613, Fold: 1, Epoch: 0)\n",
      "2025-11-13 10:13:55,557 - INFO - \n",
      "Epoch 2/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 36.15it/s, loss=0.131]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 116.38it/s]\n",
      "2025-11-13 10:14:16,951 - INFO - Train Loss: 0.1311\n",
      "2025-11-13 10:14:16,951 - INFO - Val Loss: 0.1182\n",
      "2025-11-13 10:14:16,951 - INFO - Overall - Precision: 0.4282, Recall: 0.5000, F1: 0.4613\n",
      "2025-11-13 10:14:16,952 - INFO - en - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:14:16,952 - INFO - es - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:14:16,952 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:14:16,952 - INFO - \n",
      "Epoch 3/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 36.16it/s, loss=0.129]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.77it/s]\n",
      "2025-11-13 10:14:38,350 - INFO - Train Loss: 0.1292\n",
      "2025-11-13 10:14:38,350 - INFO - Val Loss: 0.1118\n",
      "2025-11-13 10:14:38,351 - INFO - Overall - Precision: 0.4282, Recall: 0.5000, F1: 0.4613\n",
      "2025-11-13 10:14:38,351 - INFO - en - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:14:38,351 - INFO - es - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:14:38,351 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:14:38,351 - INFO - \n",
      "Epoch 4/10\n",
      "Training: 100%|██████████| 717/717 [00:20<00:00, 35.68it/s, loss=0.122]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 97.49it/s]\n",
      "2025-11-13 10:15:00,304 - INFO - Train Loss: 0.1218\n",
      "2025-11-13 10:15:00,304 - INFO - Val Loss: 0.1037\n",
      "2025-11-13 10:15:00,304 - INFO - Overall - Precision: 0.9285, Recall: 0.5024, F1: 0.4663\n",
      "2025-11-13 10:15:00,305 - INFO - en - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:15:00,305 - INFO - es - Precision: 0.9298, Recall: 0.5074, F1: 0.4767\n",
      "2025-11-13 10:15:00,305 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:15:00,312 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_0_f1_0.4613.pt\n",
      "2025-11-13 10:15:01,023 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_3_f1_0.4663.pt (F1: 0.4663, Fold: 1, Epoch: 3)\n",
      "2025-11-13 10:15:01,023 - INFO - \n",
      "Epoch 5/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 36.04it/s, loss=0.115]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.78it/s]\n",
      "2025-11-13 10:15:22,484 - INFO - Train Loss: 0.1145\n",
      "2025-11-13 10:15:22,484 - INFO - Val Loss: 0.1037\n",
      "2025-11-13 10:15:22,485 - INFO - Overall - Precision: 0.7941, Recall: 0.5182, F1: 0.4990\n",
      "2025-11-13 10:15:22,485 - INFO - en - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:15:22,485 - INFO - es - Precision: 0.8726, Recall: 0.5503, F1: 0.5569\n",
      "2025-11-13 10:15:22,485 - INFO - it - Precision: 0.5951, Recall: 0.5048, F1: 0.4743\n",
      "2025-11-13 10:15:22,492 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_0_f1_0.4615.pt\n",
      "2025-11-13 10:15:23,151 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_4_f1_0.4990.pt (F1: 0.4990, Fold: 1, Epoch: 4)\n",
      "2025-11-13 10:15:23,152 - INFO - \n",
      "Epoch 6/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 36.13it/s, loss=0.113]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.83it/s]\n",
      "2025-11-13 10:15:44,565 - INFO - Train Loss: 0.1129\n",
      "2025-11-13 10:15:44,565 - INFO - Val Loss: 0.0932\n",
      "2025-11-13 10:15:44,566 - INFO - Overall - Precision: 0.7418, Recall: 0.5800, F1: 0.6015\n",
      "2025-11-13 10:15:44,566 - INFO - en - Precision: 0.6818, Recall: 0.5301, F1: 0.5240\n",
      "2025-11-13 10:15:44,566 - INFO - es - Precision: 0.7705, Recall: 0.6140, F1: 0.6460\n",
      "2025-11-13 10:15:44,566 - INFO - it - Precision: 0.7404, Recall: 0.5965, F1: 0.6225\n",
      "2025-11-13 10:15:44,639 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_3_f1_0.4663.pt\n",
      "2025-11-13 10:15:45,320 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_5_f1_0.6015.pt (F1: 0.6015, Fold: 1, Epoch: 5)\n",
      "2025-11-13 10:15:45,321 - INFO - \n",
      "Epoch 7/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 36.11it/s, loss=0.106]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.59it/s]\n",
      "2025-11-13 10:16:06,747 - INFO - Train Loss: 0.1056\n",
      "2025-11-13 10:16:06,747 - INFO - Val Loss: 0.0984\n",
      "2025-11-13 10:16:06,747 - INFO - Overall - Precision: 0.7718, Recall: 0.5801, F1: 0.6024\n",
      "2025-11-13 10:16:06,747 - INFO - en - Precision: 0.7328, Recall: 0.5386, F1: 0.5378\n",
      "2025-11-13 10:16:06,748 - INFO - es - Precision: 0.7678, Recall: 0.6005, F1: 0.6296\n",
      "2025-11-13 10:16:06,748 - INFO - it - Precision: 0.7981, Recall: 0.6014, F1: 0.6320\n",
      "2025-11-13 10:16:06,818 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_4_f1_0.4990.pt\n",
      "2025-11-13 10:16:07,494 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_6_f1_0.6024.pt (F1: 0.6024, Fold: 1, Epoch: 6)\n",
      "2025-11-13 10:16:07,495 - INFO - \n",
      "Epoch 8/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 36.12it/s, loss=0.102] \n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.92it/s]\n",
      "2025-11-13 10:16:28,912 - INFO - Train Loss: 0.1015\n",
      "2025-11-13 10:16:28,912 - INFO - Val Loss: 0.0845\n",
      "2025-11-13 10:16:28,912 - INFO - Overall - Precision: 0.7736, Recall: 0.6718, F1: 0.7049\n",
      "2025-11-13 10:16:28,912 - INFO - en - Precision: 0.7232, Recall: 0.6194, F1: 0.6465\n",
      "2025-11-13 10:16:28,912 - INFO - es - Precision: 0.7987, Recall: 0.7170, F1: 0.7479\n",
      "2025-11-13 10:16:28,913 - INFO - it - Precision: 0.7896, Recall: 0.6798, F1: 0.7152\n",
      "2025-11-13 10:16:28,984 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_5_f1_0.6015.pt\n",
      "2025-11-13 10:16:29,928 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_7_f1_0.7049.pt (F1: 0.7049, Fold: 1, Epoch: 7)\n",
      "2025-11-13 10:16:29,929 - INFO - \n",
      "Epoch 9/10\n",
      "Training: 100%|██████████| 717/717 [00:20<00:00, 35.76it/s, loss=0.0985]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.25it/s]\n",
      "2025-11-13 10:16:51,552 - INFO - Train Loss: 0.0985\n",
      "2025-11-13 10:16:51,553 - INFO - Val Loss: 0.0945\n",
      "2025-11-13 10:16:51,553 - INFO - Overall - Precision: 0.8282, Recall: 0.6585, F1: 0.7014\n",
      "2025-11-13 10:16:51,553 - INFO - en - Precision: 0.8729, Recall: 0.6268, F1: 0.6689\n",
      "2025-11-13 10:16:51,553 - INFO - es - Precision: 0.8192, Recall: 0.6728, F1: 0.7147\n",
      "2025-11-13 10:16:51,553 - INFO - it - Precision: 0.8125, Recall: 0.6762, F1: 0.7165\n",
      "2025-11-13 10:16:51,553 - INFO - \n",
      "Epoch 10/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 36.10it/s, loss=0.0936]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.79it/s]\n",
      "2025-11-13 10:17:12,984 - INFO - Train Loss: 0.0936\n",
      "2025-11-13 10:17:12,984 - INFO - Val Loss: 0.0818\n",
      "2025-11-13 10:17:12,985 - INFO - Overall - Precision: 0.7741, Recall: 0.7062, F1: 0.7325\n",
      "2025-11-13 10:17:12,985 - INFO - en - Precision: 0.7319, Recall: 0.6941, F1: 0.7102\n",
      "2025-11-13 10:17:12,985 - INFO - es - Precision: 0.8003, Recall: 0.7305, F1: 0.7583\n",
      "2025-11-13 10:17:12,985 - INFO - it - Precision: 0.7994, Recall: 0.6943, F1: 0.7299\n",
      "2025-11-13 10:17:13,054 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_6_f1_0.6024.pt\n",
      "2025-11-13 10:17:15,034 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_9_f1_0.7325.pt (F1: 0.7325, Fold: 1, Epoch: 9)\n",
      "2025-11-13 10:17:15,035 - INFO - \n",
      "================================================================================\n",
      "2025-11-13 10:17:15,035 - INFO - Fold 3/5\n",
      "2025-11-13 10:17:15,036 - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 2:\n",
      "  Train: 821 positive samples\n",
      "  Val:   206 positive samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-11-13 10:17:18,014 - INFO - Froze: Embeddings + First 3 Encoder Layers\n",
      "2025-11-13 10:17:18,014 - INFO - Trainable: Classification Head + Remaining Encoder Layers\n",
      "2025-11-13 10:17:18,015 - INFO - Trainable parameters: 64,382,978 / 278,045,186 (23.16%)\n",
      "2025-11-13 10:17:18,016 - INFO - Label weights: {0: 0.5835198372329603, 1: 3.4933008526187574}\n",
      "2025-11-13 10:17:18,016 - INFO - Language weights: {'es': 1.0, 'en': 1.0, 'it': 1.0}\n",
      "2025-11-13 10:17:18,016 - INFO - Pos weight (for BCE): 5.9866\n",
      "2025-11-13 10:17:18,018 - INFO - \n",
      "Epoch 1/10\n",
      "Training: 100%|██████████| 717/717 [00:20<00:00, 35.74it/s, loss=0.133]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.31it/s]\n",
      "2025-11-13 10:17:39,659 - INFO - Train Loss: 0.1333\n",
      "2025-11-13 10:17:39,660 - INFO - Val Loss: 0.1159\n",
      "2025-11-13 10:17:39,660 - INFO - Overall - Precision: 0.4282, Recall: 0.5000, F1: 0.4613\n",
      "2025-11-13 10:17:39,660 - INFO - en - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:17:39,660 - INFO - es - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:17:39,660 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:17:39,667 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_0_f1_0.4613.pt\n",
      "2025-11-13 10:17:40,322 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_0_f1_0.4613.pt (F1: 0.4613, Fold: 2, Epoch: 0)\n",
      "2025-11-13 10:17:40,322 - INFO - \n",
      "Epoch 2/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 35.99it/s, loss=0.133]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.27it/s]\n",
      "2025-11-13 10:18:01,819 - INFO - Train Loss: 0.1326\n",
      "2025-11-13 10:18:01,819 - INFO - Val Loss: 0.1199\n",
      "2025-11-13 10:18:01,819 - INFO - Overall - Precision: 0.4282, Recall: 0.5000, F1: 0.4613\n",
      "2025-11-13 10:18:01,819 - INFO - en - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:18:01,819 - INFO - es - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:18:01,819 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:18:01,819 - INFO - \n",
      "Epoch 3/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 36.05it/s, loss=0.129]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 116.78it/s]\n",
      "2025-11-13 10:18:23,263 - INFO - Train Loss: 0.1285\n",
      "2025-11-13 10:18:23,264 - INFO - Val Loss: 0.1112\n",
      "2025-11-13 10:18:23,264 - INFO - Overall - Precision: 0.4282, Recall: 0.5000, F1: 0.4613\n",
      "2025-11-13 10:18:23,264 - INFO - en - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:18:23,264 - INFO - es - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-13 10:18:23,264 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:18:23,264 - INFO - \n",
      "Epoch 4/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 36.02it/s, loss=0.123]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 114.92it/s]\n",
      "2025-11-13 10:18:44,752 - INFO - Train Loss: 0.1226\n",
      "2025-11-13 10:18:44,752 - INFO - Val Loss: 0.1088\n",
      "2025-11-13 10:18:44,752 - INFO - Overall - Precision: 0.9285, Recall: 0.5024, F1: 0.4663\n",
      "2025-11-13 10:18:44,752 - INFO - en - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:18:44,753 - INFO - es - Precision: 0.9298, Recall: 0.5074, F1: 0.4767\n",
      "2025-11-13 10:18:44,753 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:18:45,397 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_3_f1_0.4663.pt (F1: 0.4663, Fold: 2, Epoch: 3)\n",
      "2025-11-13 10:18:45,397 - INFO - \n",
      "Epoch 5/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 36.04it/s, loss=0.116]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.45it/s]\n",
      "2025-11-13 10:19:06,863 - INFO - Train Loss: 0.1161\n",
      "2025-11-13 10:19:06,864 - INFO - Val Loss: 0.0996\n",
      "2025-11-13 10:19:06,864 - INFO - Overall - Precision: 0.7118, Recall: 0.5190, F1: 0.5020\n",
      "2025-11-13 10:19:06,864 - INFO - en - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:19:06,864 - INFO - es - Precision: 0.7178, Recall: 0.5258, F1: 0.5153\n",
      "2025-11-13 10:19:06,864 - INFO - it - Precision: 0.7095, Recall: 0.5313, F1: 0.5254\n",
      "2025-11-13 10:19:07,521 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_4_f1_0.5020.pt (F1: 0.5020, Fold: 2, Epoch: 4)\n",
      "2025-11-13 10:19:07,522 - INFO - \n",
      "Epoch 6/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 35.99it/s, loss=0.11] \n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.13it/s]\n",
      "2025-11-13 10:19:29,019 - INFO - Train Loss: 0.1104\n",
      "2025-11-13 10:19:29,019 - INFO - Val Loss: 0.0982\n",
      "2025-11-13 10:19:29,019 - INFO - Overall - Precision: 0.7731, Recall: 0.5558, F1: 0.5661\n",
      "2025-11-13 10:19:29,020 - INFO - en - Precision: 0.8314, Recall: 0.5278, F1: 0.5167\n",
      "2025-11-13 10:19:29,020 - INFO - es - Precision: 0.7436, Recall: 0.5723, F1: 0.5911\n",
      "2025-11-13 10:19:29,020 - INFO - it - Precision: 0.7936, Recall: 0.5676, F1: 0.5844\n",
      "2025-11-13 10:19:29,692 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_5_f1_0.5661.pt (F1: 0.5661, Fold: 2, Epoch: 5)\n",
      "2025-11-13 10:19:29,692 - INFO - \n",
      "Epoch 7/10\n",
      "Training: 100%|██████████| 717/717 [00:19<00:00, 35.92it/s, loss=0.102]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.73it/s]\n",
      "2025-11-13 10:19:51,219 - INFO - Train Loss: 0.1023\n",
      "2025-11-13 10:19:51,219 - INFO - Val Loss: 0.0983\n",
      "2025-11-13 10:19:51,219 - INFO - Overall - Precision: 0.7850, Recall: 0.6076, F1: 0.6392\n",
      "2025-11-13 10:19:51,220 - INFO - en - Precision: 0.7982, Recall: 0.6014, F1: 0.6321\n",
      "2025-11-13 10:19:51,220 - INFO - es - Precision: 0.7678, Recall: 0.6005, F1: 0.6296\n",
      "2025-11-13 10:19:51,220 - INFO - it - Precision: 0.7897, Recall: 0.6207, F1: 0.6552\n",
      "2025-11-13 10:19:51,930 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_6_f1_0.6392.pt (F1: 0.6392, Fold: 2, Epoch: 6)\n",
      "2025-11-13 10:19:51,931 - INFO - \n",
      "Epoch 8/10\n",
      "Training: 100%|██████████| 717/717 [00:20<00:00, 35.70it/s, loss=0.102] \n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.12it/s]\n",
      "2025-11-13 10:20:13,591 - INFO - Train Loss: 0.1021\n",
      "2025-11-13 10:20:13,591 - INFO - Val Loss: 0.0859\n",
      "2025-11-13 10:20:13,591 - INFO - Overall - Precision: 0.7763, Recall: 0.6787, F1: 0.7114\n",
      "2025-11-13 10:20:13,591 - INFO - en - Precision: 0.8024, Recall: 0.6484, F1: 0.6874\n",
      "2025-11-13 10:20:13,591 - INFO - es - Precision: 0.7690, Recall: 0.6729, F1: 0.7049\n",
      "2025-11-13 10:20:13,591 - INFO - it - Precision: 0.7690, Recall: 0.7147, F1: 0.7369\n",
      "2025-11-13 10:20:13,598 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_7_f1_0.7049.pt\n",
      "2025-11-13 10:20:14,290 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_7_f1_0.7114.pt (F1: 0.7114, Fold: 2, Epoch: 7)\n",
      "2025-11-13 10:20:14,290 - INFO - \n",
      "Epoch 9/10\n",
      "Training: 100%|██████████| 717/717 [00:20<00:00, 35.66it/s, loss=0.0972]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 114.70it/s]\n",
      "2025-11-13 10:20:35,977 - INFO - Train Loss: 0.0972\n",
      "2025-11-13 10:20:35,977 - INFO - Val Loss: 0.1020\n",
      "2025-11-13 10:20:35,977 - INFO - Overall - Precision: 0.8318, Recall: 0.6521, F1: 0.6950\n",
      "2025-11-13 10:20:35,977 - INFO - en - Precision: 0.8162, Recall: 0.6364, F1: 0.6759\n",
      "2025-11-13 10:20:35,977 - INFO - es - Precision: 0.8153, Recall: 0.6520, F1: 0.6930\n",
      "2025-11-13 10:20:35,977 - INFO - it - Precision: 0.8637, Recall: 0.6678, F1: 0.7158\n",
      "2025-11-13 10:20:35,978 - INFO - \n",
      "Epoch 10/10\n",
      "Training: 100%|██████████| 717/717 [00:20<00:00, 35.56it/s, loss=0.0927]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 114.93it/s]\n",
      "2025-11-13 10:20:57,722 - INFO - Train Loss: 0.0927\n",
      "2025-11-13 10:20:57,723 - INFO - Val Loss: 0.0902\n",
      "2025-11-13 10:20:57,723 - INFO - Overall - Precision: 0.8059, Recall: 0.7050, F1: 0.7404\n",
      "2025-11-13 10:20:57,723 - INFO - en - Precision: 0.7845, Recall: 0.6726, F1: 0.7078\n",
      "2025-11-13 10:20:57,723 - INFO - es - Precision: 0.8274, Recall: 0.7010, F1: 0.7422\n",
      "2025-11-13 10:20:57,723 - INFO - it - Precision: 0.8074, Recall: 0.7413, F1: 0.7682\n",
      "2025-11-13 10:20:57,788 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_7_f1_0.7114.pt\n",
      "2025-11-13 10:20:58,467 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_9_f1_0.7404.pt (F1: 0.7404, Fold: 2, Epoch: 9)\n",
      "2025-11-13 10:20:58,468 - INFO - \n",
      "================================================================================\n",
      "2025-11-13 10:20:58,468 - INFO - Fold 4/5\n",
      "2025-11-13 10:20:58,468 - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 3:\n",
      "  Train: 820 positive samples\n",
      "  Val:   207 positive samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-11-13 10:21:02,090 - INFO - Froze: Embeddings + First 3 Encoder Layers\n",
      "2025-11-13 10:21:02,091 - INFO - Trainable: Classification Head + Remaining Encoder Layers\n",
      "2025-11-13 10:21:02,091 - INFO - Trainable parameters: 64,382,978 / 278,045,186 (23.16%)\n",
      "2025-11-13 10:21:02,092 - INFO - Label weights: {0: 0.5834011391375101, 1: 3.497560975609756}\n",
      "2025-11-13 10:21:02,092 - INFO - Language weights: {'es': 1.0, 'en': 1.0, 'it': 1.0}\n",
      "2025-11-13 10:21:02,093 - INFO - Pos weight (for BCE): 5.9951\n",
      "2025-11-13 10:21:02,094 - INFO - \n",
      "Epoch 1/10\n",
      "Training: 100%|██████████| 717/717 [00:20<00:00, 35.70it/s, loss=0.135]\n",
      "Validating: 100%|██████████| 180/180 [00:01<00:00, 115.16it/s]\n",
      "2025-11-13 10:21:23,760 - INFO - Train Loss: 0.1350\n",
      "2025-11-13 10:21:23,760 - INFO - Val Loss: 0.1145\n",
      "2025-11-13 10:21:23,760 - INFO - Overall - Precision: 0.4279, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:21:23,761 - INFO - en - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:21:23,761 - INFO - es - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:21:23,761 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:21:23,775 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_0_f1_0.4611.pt\n",
      "2025-11-13 10:21:24,630 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_0_f1_0.4611.pt (F1: 0.4611, Fold: 3, Epoch: 0)\n",
      "2025-11-13 10:21:24,631 - INFO - \n",
      "Epoch 2/10\n",
      "Training: 100%|██████████| 717/717 [00:32<00:00, 21.83it/s, loss=0.131]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 43.96it/s]\n",
      "2025-11-13 10:22:01,588 - INFO - Train Loss: 0.1307\n",
      "2025-11-13 10:22:01,588 - INFO - Val Loss: 0.1175\n",
      "2025-11-13 10:22:01,588 - INFO - Overall - Precision: 0.4279, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:22:01,588 - INFO - en - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:22:01,589 - INFO - es - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:22:01,589 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:22:01,589 - INFO - \n",
      "Epoch 3/10\n",
      "Training: 100%|██████████| 717/717 [00:43<00:00, 16.31it/s, loss=0.128]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 44.42it/s]\n",
      "2025-11-13 10:22:49,604 - INFO - Train Loss: 0.1277\n",
      "2025-11-13 10:22:49,604 - INFO - Val Loss: 0.1146\n",
      "2025-11-13 10:22:49,604 - INFO - Overall - Precision: 0.4279, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:22:49,604 - INFO - en - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:22:49,604 - INFO - es - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:22:49,605 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:22:49,605 - INFO - \n",
      "Epoch 4/10\n",
      "Training: 100%|██████████| 717/717 [00:44<00:00, 16.16it/s, loss=0.122]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 42.88it/s]\n",
      "2025-11-13 10:23:38,181 - INFO - Train Loss: 0.1215\n",
      "2025-11-13 10:23:38,182 - INFO - Val Loss: 0.1065\n",
      "2025-11-13 10:23:38,182 - INFO - Overall - Precision: 0.9288, Recall: 0.5072, F1: 0.4759\n",
      "2025-11-13 10:23:38,182 - INFO - en - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:23:38,182 - INFO - es - Precision: 0.9289, Recall: 0.5072, F1: 0.4760\n",
      "2025-11-13 10:23:38,182 - INFO - it - Precision: 0.9296, Recall: 0.5145, F1: 0.4903\n",
      "2025-11-13 10:23:38,891 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_3_f1_0.4759.pt (F1: 0.4759, Fold: 3, Epoch: 3)\n",
      "2025-11-13 10:23:38,892 - INFO - \n",
      "Epoch 5/10\n",
      "Training: 100%|██████████| 717/717 [00:44<00:00, 16.29it/s, loss=0.116]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 44.43it/s]\n",
      "2025-11-13 10:24:26,964 - INFO - Train Loss: 0.1158\n",
      "2025-11-13 10:24:26,965 - INFO - Val Loss: 0.1001\n",
      "2025-11-13 10:24:26,965 - INFO - Overall - Precision: 0.8460, Recall: 0.5117, F1: 0.4853\n",
      "2025-11-13 10:24:26,965 - INFO - en - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:24:26,965 - INFO - es - Precision: 0.8055, Recall: 0.5205, F1: 0.5032\n",
      "2025-11-13 10:24:26,965 - INFO - it - Precision: 0.9296, Recall: 0.5145, F1: 0.4903\n",
      "2025-11-13 10:24:27,639 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_4_f1_0.4853.pt (F1: 0.4853, Fold: 3, Epoch: 4)\n",
      "2025-11-13 10:24:27,639 - INFO - \n",
      "Epoch 6/10\n",
      "Training: 100%|██████████| 717/717 [00:44<00:00, 16.26it/s, loss=0.112]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 44.27it/s]\n",
      "2025-11-13 10:25:15,825 - INFO - Train Loss: 0.1119\n",
      "2025-11-13 10:25:15,825 - INFO - Val Loss: 0.0958\n",
      "2025-11-13 10:25:15,825 - INFO - Overall - Precision: 0.8080, Recall: 0.5660, F1: 0.5821\n",
      "2025-11-13 10:25:15,825 - INFO - en - Precision: 0.8489, Recall: 0.5350, F1: 0.5298\n",
      "2025-11-13 10:25:15,825 - INFO - es - Precision: 0.9004, Recall: 0.5857, F1: 0.6132\n",
      "2025-11-13 10:25:15,825 - INFO - it - Precision: 0.7378, Recall: 0.5772, F1: 0.5973\n",
      "2025-11-13 10:25:16,481 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_5_f1_0.5821.pt (F1: 0.5821, Fold: 3, Epoch: 5)\n",
      "2025-11-13 10:25:16,481 - INFO - \n",
      "Epoch 7/10\n",
      "Training: 100%|██████████| 717/717 [00:44<00:00, 16.18it/s, loss=0.107]\n",
      "Validating: 100%|██████████| 180/180 [00:03<00:00, 45.66it/s]\n",
      "2025-11-13 10:26:04,736 - INFO - Train Loss: 0.1068\n",
      "2025-11-13 10:26:04,736 - INFO - Val Loss: 0.0930\n",
      "2025-11-13 10:26:04,736 - INFO - Overall - Precision: 0.8201, Recall: 0.6187, F1: 0.6553\n",
      "2025-11-13 10:26:04,736 - INFO - en - Precision: 0.8384, Recall: 0.5833, F1: 0.6085\n",
      "2025-11-13 10:26:04,737 - INFO - es - Precision: 0.8509, Recall: 0.6461, F1: 0.6903\n",
      "2025-11-13 10:26:04,737 - INFO - it - Precision: 0.7837, Recall: 0.6267, F1: 0.6615\n",
      "2025-11-13 10:26:05,415 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_6_f1_0.6553.pt (F1: 0.6553, Fold: 3, Epoch: 6)\n",
      "2025-11-13 10:26:05,415 - INFO - \n",
      "Epoch 8/10\n",
      "Training: 100%|██████████| 717/717 [00:44<00:00, 16.28it/s, loss=0.0998]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 43.87it/s]\n",
      "2025-11-13 10:26:53,572 - INFO - Train Loss: 0.0998\n",
      "2025-11-13 10:26:53,572 - INFO - Val Loss: 0.1030\n",
      "2025-11-13 10:26:53,572 - INFO - Overall - Precision: 0.8570, Recall: 0.6396, F1: 0.6834\n",
      "2025-11-13 10:26:53,572 - INFO - en - Precision: 0.8353, Recall: 0.6243, F1: 0.6632\n",
      "2025-11-13 10:26:53,573 - INFO - es - Precision: 0.9067, Recall: 0.6570, F1: 0.7082\n",
      "2025-11-13 10:26:53,573 - INFO - it - Precision: 0.8304, Recall: 0.6376, F1: 0.6786\n",
      "2025-11-13 10:26:54,220 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_7_f1_0.6834.pt (F1: 0.6834, Fold: 3, Epoch: 7)\n",
      "2025-11-13 10:26:54,221 - INFO - \n",
      "Epoch 9/10\n",
      "Training: 100%|██████████| 717/717 [00:44<00:00, 16.25it/s, loss=0.101] \n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 44.12it/s]\n",
      "2025-11-13 10:27:42,427 - INFO - Train Loss: 0.1012\n",
      "2025-11-13 10:27:42,428 - INFO - Val Loss: 0.0849\n",
      "2025-11-13 10:27:42,428 - INFO - Overall - Precision: 0.7950, Recall: 0.6762, F1: 0.7132\n",
      "2025-11-13 10:27:42,428 - INFO - en - Precision: 0.8125, Recall: 0.6762, F1: 0.7165\n",
      "2025-11-13 10:27:42,428 - INFO - es - Precision: 0.7934, Recall: 0.6738, F1: 0.7107\n",
      "2025-11-13 10:27:42,428 - INFO - it - Precision: 0.7812, Recall: 0.6785, F1: 0.7124\n",
      "2025-11-13 10:27:43,079 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_8_f1_0.7132.pt (F1: 0.7132, Fold: 3, Epoch: 8)\n",
      "2025-11-13 10:27:43,079 - INFO - \n",
      "Epoch 10/10\n",
      "Training: 100%|██████████| 717/717 [00:44<00:00, 16.21it/s, loss=0.0933]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 43.39it/s]\n",
      "2025-11-13 10:28:31,460 - INFO - Train Loss: 0.0932\n",
      "2025-11-13 10:28:31,461 - INFO - Val Loss: 0.1024\n",
      "2025-11-13 10:28:31,461 - INFO - Overall - Precision: 0.8123, Recall: 0.6850, F1: 0.7247\n",
      "2025-11-13 10:28:31,461 - INFO - en - Precision: 0.7896, Recall: 0.6798, F1: 0.7152\n",
      "2025-11-13 10:28:31,461 - INFO - es - Precision: 0.8276, Recall: 0.6847, F1: 0.7272\n",
      "2025-11-13 10:28:31,461 - INFO - it - Precision: 0.8218, Recall: 0.6907, F1: 0.7316\n",
      "2025-11-13 10:28:32,169 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_9_f1_0.7247.pt (F1: 0.7247, Fold: 3, Epoch: 9)\n",
      "2025-11-13 10:28:32,169 - INFO - \n",
      "================================================================================\n",
      "2025-11-13 10:28:32,169 - INFO - Fold 5/5\n",
      "2025-11-13 10:28:32,170 - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 4:\n",
      "  Train: 821 positive samples\n",
      "  Val:   207 positive samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-11-13 10:28:35,664 - INFO - Froze: Embeddings + First 3 Encoder Layers\n",
      "2025-11-13 10:28:35,665 - INFO - Trainable: Classification Head + Remaining Encoder Layers\n",
      "2025-11-13 10:28:35,665 - INFO - Trainable parameters: 64,382,978 / 278,045,186 (23.16%)\n",
      "2025-11-13 10:28:35,666 - INFO - Label weights: {0: 0.5835028478437754, 1: 3.4939098660170522}\n",
      "2025-11-13 10:28:35,666 - INFO - Language weights: {'it': 0.9996514464970374, 'es': 1.0001742767514814, 'en': 1.0001742767514814}\n",
      "2025-11-13 10:28:35,667 - INFO - Pos weight (for BCE): 5.9878\n",
      "2025-11-13 10:28:35,668 - INFO - \n",
      "Epoch 1/10\n",
      "Training: 100%|██████████| 718/718 [00:44<00:00, 16.24it/s, loss=0.134]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 43.75it/s]\n",
      "2025-11-13 10:29:24,029 - INFO - Train Loss: 0.1339\n",
      "2025-11-13 10:29:24,029 - INFO - Val Loss: 0.1159\n",
      "2025-11-13 10:29:24,029 - INFO - Overall - Precision: 0.4279, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:29:24,029 - INFO - en - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:29:24,029 - INFO - es - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:29:24,029 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:29:24,036 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_0_f1_0.4611.pt\n",
      "2025-11-13 10:29:24,681 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_0_f1_0.4611.pt (F1: 0.4611, Fold: 4, Epoch: 0)\n",
      "2025-11-13 10:29:24,681 - INFO - \n",
      "Epoch 2/10\n",
      "Training: 100%|██████████| 718/718 [00:44<00:00, 16.13it/s, loss=0.133]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 41.31it/s]\n",
      "2025-11-13 10:30:13,560 - INFO - Train Loss: 0.1332\n",
      "2025-11-13 10:30:13,560 - INFO - Val Loss: 0.1189\n",
      "2025-11-13 10:30:13,560 - INFO - Overall - Precision: 0.4279, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:30:13,560 - INFO - en - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:30:13,560 - INFO - es - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:30:13,560 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:30:13,561 - INFO - \n",
      "Epoch 3/10\n",
      "Training: 100%|██████████| 718/718 [00:44<00:00, 16.19it/s, loss=0.131]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 43.70it/s]\n",
      "2025-11-13 10:31:02,048 - INFO - Train Loss: 0.1306\n",
      "2025-11-13 10:31:02,048 - INFO - Val Loss: 0.1120\n",
      "2025-11-13 10:31:02,048 - INFO - Overall - Precision: 0.4279, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:31:02,049 - INFO - en - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:31:02,049 - INFO - es - Precision: 0.4280, Recall: 0.5000, F1: 0.4612\n",
      "2025-11-13 10:31:02,049 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:31:02,049 - INFO - \n",
      "Epoch 4/10\n",
      "Training: 100%|██████████| 718/718 [00:44<00:00, 16.09it/s, loss=0.121]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 42.56it/s]\n",
      "2025-11-13 10:31:50,926 - INFO - Train Loss: 0.1211\n",
      "2025-11-13 10:31:50,926 - INFO - Val Loss: 0.1047\n",
      "2025-11-13 10:31:50,926 - INFO - Overall - Precision: 0.9282, Recall: 0.5024, F1: 0.4661\n",
      "2025-11-13 10:31:50,926 - INFO - en - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:31:50,926 - INFO - es - Precision: 0.9289, Recall: 0.5072, F1: 0.4760\n",
      "2025-11-13 10:31:50,926 - INFO - it - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-13 10:31:51,575 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_3_f1_0.4661.pt (F1: 0.4661, Fold: 4, Epoch: 3)\n",
      "2025-11-13 10:31:51,576 - INFO - \n",
      "Epoch 5/10\n",
      "Training: 100%|██████████| 718/718 [00:44<00:00, 16.11it/s, loss=0.113]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 42.96it/s]\n",
      "2025-11-13 10:32:40,345 - INFO - Train Loss: 0.1127\n",
      "2025-11-13 10:32:40,345 - INFO - Val Loss: 0.0960\n",
      "2025-11-13 10:32:40,345 - INFO - Overall - Precision: 0.7634, Recall: 0.5177, F1: 0.4982\n",
      "2025-11-13 10:32:40,345 - INFO - en - Precision: 0.9287, Recall: 0.5072, F1: 0.4759\n",
      "2025-11-13 10:32:40,345 - INFO - es - Precision: 0.8055, Recall: 0.5205, F1: 0.5032\n",
      "2025-11-13 10:32:40,345 - INFO - it - Precision: 0.7167, Recall: 0.5253, F1: 0.5140\n",
      "2025-11-13 10:32:41,019 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_4_f1_0.4982.pt (F1: 0.4982, Fold: 4, Epoch: 4)\n",
      "2025-11-13 10:32:41,019 - INFO - \n",
      "Epoch 6/10\n",
      "Training: 100%|██████████| 718/718 [00:44<00:00, 16.19it/s, loss=0.113] \n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 43.74it/s]\n",
      "2025-11-13 10:33:29,498 - INFO - Train Loss: 0.1127\n",
      "2025-11-13 10:33:29,498 - INFO - Val Loss: 0.0999\n",
      "2025-11-13 10:33:29,498 - INFO - Overall - Precision: 0.8181, Recall: 0.5732, F1: 0.5932\n",
      "2025-11-13 10:33:29,498 - INFO - en - Precision: 0.9296, Recall: 0.5145, F1: 0.4903\n",
      "2025-11-13 10:33:29,499 - INFO - es - Precision: 0.7715, Recall: 0.5796, F1: 0.6018\n",
      "2025-11-13 10:33:29,499 - INFO - it - Precision: 0.8532, Recall: 0.6255, F1: 0.6660\n",
      "2025-11-13 10:33:30,161 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_5_f1_0.5932.pt (F1: 0.5932, Fold: 4, Epoch: 5)\n",
      "2025-11-13 10:33:30,161 - INFO - \n",
      "Epoch 7/10\n",
      "Training: 100%|██████████| 718/718 [00:44<00:00, 16.09it/s, loss=0.105]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 42.13it/s]\n",
      "2025-11-13 10:34:19,057 - INFO - Train Loss: 0.1047\n",
      "2025-11-13 10:34:19,057 - INFO - Val Loss: 0.0960\n",
      "2025-11-13 10:34:19,057 - INFO - Overall - Precision: 0.7793, Recall: 0.6022, F1: 0.6320\n",
      "2025-11-13 10:34:19,058 - INFO - en - Precision: 0.7425, Recall: 0.5712, F1: 0.5890\n",
      "2025-11-13 10:34:19,058 - INFO - es - Precision: 0.7580, Recall: 0.5917, F1: 0.6175\n",
      "2025-11-13 10:34:19,058 - INFO - it - Precision: 0.8217, Recall: 0.6436, F1: 0.6845\n",
      "2025-11-13 10:34:19,711 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_6_f1_0.6320.pt (F1: 0.6320, Fold: 4, Epoch: 6)\n",
      "2025-11-13 10:34:19,712 - INFO - \n",
      "Epoch 8/10\n",
      "Training: 100%|██████████| 718/718 [00:44<00:00, 16.14it/s, loss=0.0986]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 43.54it/s]\n",
      "2025-11-13 10:35:08,347 - INFO - Train Loss: 0.0986\n",
      "2025-11-13 10:35:08,347 - INFO - Val Loss: 0.0875\n",
      "2025-11-13 10:35:08,347 - INFO - Overall - Precision: 0.7518, Recall: 0.6528, F1: 0.6834\n",
      "2025-11-13 10:35:08,347 - INFO - en - Precision: 0.7154, Recall: 0.6121, F1: 0.6378\n",
      "2025-11-13 10:35:08,347 - INFO - es - Precision: 0.7786, Recall: 0.6846, F1: 0.7169\n",
      "2025-11-13 10:35:08,347 - INFO - it - Precision: 0.7545, Recall: 0.6616, F1: 0.6918\n",
      "2025-11-13 10:35:09,005 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_7_f1_0.6834.pt (F1: 0.6834, Fold: 4, Epoch: 7)\n",
      "2025-11-13 10:35:09,006 - INFO - \n",
      "Epoch 9/10\n",
      "Training: 100%|██████████| 718/718 [00:44<00:00, 16.21it/s, loss=0.0952]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 43.58it/s]\n",
      "2025-11-13 10:35:57,451 - INFO - Train Loss: 0.0951\n",
      "2025-11-13 10:35:57,451 - INFO - Val Loss: 0.1026\n",
      "2025-11-13 10:35:57,452 - INFO - Overall - Precision: 0.8080, Recall: 0.6267, F1: 0.6639\n",
      "2025-11-13 10:35:57,452 - INFO - en - Precision: 0.7287, Recall: 0.5952, F1: 0.6201\n",
      "2025-11-13 10:35:57,452 - INFO - es - Precision: 0.8408, Recall: 0.6521, F1: 0.6960\n",
      "2025-11-13 10:35:57,452 - INFO - it - Precision: 0.8581, Recall: 0.6328, F1: 0.6753\n",
      "2025-11-13 10:35:57,452 - INFO - \n",
      "Epoch 10/10\n",
      "Training: 100%|██████████| 718/718 [00:44<00:00, 16.10it/s, loss=0.0938]\n",
      "Validating: 100%|██████████| 180/180 [00:04<00:00, 44.43it/s]\n",
      "2025-11-13 10:36:46,110 - INFO - Train Loss: 0.0937\n",
      "2025-11-13 10:36:46,110 - INFO - Val Loss: 0.0962\n",
      "2025-11-13 10:36:46,110 - INFO - Overall - Precision: 0.8320, Recall: 0.6581, F1: 0.7014\n",
      "2025-11-13 10:36:46,111 - INFO - en - Precision: 0.7719, Recall: 0.6255, F1: 0.6589\n",
      "2025-11-13 10:36:46,111 - INFO - es - Precision: 0.8947, Recall: 0.6703, F1: 0.7222\n",
      "2025-11-13 10:36:46,111 - INFO - it - Precision: 0.8339, Recall: 0.6786, F1: 0.7225\n",
      "2025-11-13 10:36:46,777 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_9_f1_0.7014.pt (F1: 0.7014, Fold: 4, Epoch: 9)\n",
      "2025-11-13 10:36:46,786 - INFO - \n",
      "Results saved to: ../results/roberta-fine-tune/original_and_augumented/training_results.csv\n",
      "2025-11-13 10:36:46,786 - INFO - \n",
      "================================================================================\n",
      "2025-11-13 10:36:46,787 - INFO - Best Models Saved:\n",
      "2025-11-13 10:36:46,787 - INFO - ================================================================================\n",
      "2025-11-13 10:36:46,787 - INFO - Fold 2, Epoch 9: F1=0.7404 -> ../fine_tuned_models/checkpoints/fold_2_epoch_9_f1_0.7404.pt\n",
      "2025-11-13 10:36:46,787 - INFO - Fold 1, Epoch 9: F1=0.7325 -> ../fine_tuned_models/checkpoints/fold_1_epoch_9_f1_0.7325.pt\n"
     ]
    }
   ],
   "source": [
    "main(merged_data, Config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c141d468-18bd-4a32-878e-ea24c52d6ee7",
   "metadata": {},
   "source": [
    "### Visualizing Fine-Tune Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f968616-5ab7-4911-a664-6746ac34d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../results/roberta-fine-tune/original_and_augumented/training_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669256a3-d5ef-427e-97fa-5649a8d91ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../figures/f1_vs_fold_augmented.svg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_plot = alt.Chart(df).mark_line(point=True, size=3).encode(\n",
    "    x=alt.X('epoch:Q', title='Epoch'),\n",
    "    y=alt.Y('overall_macro_f1:Q', title='Macro F1 Score', scale=alt.Scale(domain=[0.3, 0.8])),\n",
    "    color=alt.Color('fold:N', title='Fold'),\n",
    "    tooltip=['fold:N', 'epoch:Q', alt.Tooltip('overall_macro_f1:Q', format='.4f')]\n",
    ").properties(width=600, height=300, title='Overall F1 Score by Fold')\n",
    "f1_plot.save(os.path.join(figures_root, 'f1_vs_fold_augmented.svg'))\n",
    "os.path.join(figures_root, 'f1_vs_fold_augmented.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7aeffa-3c2b-4e12-9d73-176d7f020dc9",
   "metadata": {},
   "source": [
    "![](../figures/f1_vs_fold_augmented.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc1abcc-a363-4160-b763-684a111b67cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../figures/loss_augmented.svg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_data = df[['fold', 'epoch', 'train_loss', 'val_loss']].melt(\n",
    "    id_vars=['fold', 'epoch'], var_name='loss_type', value_name='loss'\n",
    ")\n",
    "\n",
    "loss_plot = alt.Chart(loss_data).mark_line(point=True).encode(\n",
    "    x='epoch:Q', y='loss:Q', color='loss_type:N', strokeDash='fold:N',\n",
    "    tooltip=['fold:N', 'epoch:Q', 'loss_type:N', alt.Tooltip('loss:Q', format='.4f')]\n",
    ").properties(width=600, height=300, title='Training & Validation Loss')\n",
    "\n",
    "loss_plot.save(os.path.join(figures_root, 'loss_augmented.svg'))\n",
    "os.path.join(figures_root, 'loss_augmented.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53149bf7-3ed2-45af-8954-1af12c737f15",
   "metadata": {},
   "source": [
    "![](../figures/loss_augmented.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db4cc8b-762d-46a5-ae47-122d777394a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../figures/f1_vs_lang_augmented.svg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_data = df[['fold', 'epoch', 'en_macro_f1', 'es_macro_f1', 'it_macro_f1']].melt(\n",
    "    id_vars=['fold', 'epoch'], var_name='language', value_name='f1'\n",
    ")\n",
    "lang_data['language'] = lang_data['language'].str.replace('_macro_f1', '').str.upper()\n",
    "\n",
    "lang_plot = alt.Chart(lang_data).mark_line(point=True).encode(\n",
    "    x='epoch:Q', y=alt.Y('f1:Q', scale=alt.Scale(domain=[0.4, 0.95])), color='language:N', strokeDash='fold:N',\n",
    "    tooltip=['fold:N', 'epoch:Q', 'language:N', alt.Tooltip('f1:Q', format='.4f')]\n",
    ").properties(width=600, height=300, title='F1 by Language')\n",
    "\n",
    "lang_plot.save(os.path.join(figures_root, 'f1_vs_lang_augmented.svg'))\n",
    "os.path.join(figures_root, 'f1_vs_lang_augmented.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e06673-7cd3-44fb-b8e4-af3a8e495fbd",
   "metadata": {},
   "source": [
    "![](../figures/f1_vs_lang_augmented.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b491471f-fb74-4ab7-bf4c-d9fbc0663cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../figures/fold_vs_epoch_augmented.svg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_data = df[['fold', 'epoch', 'overall_macro_precision', 'overall_macro_recall', 'overall_macro_f1']].melt(\n",
    "    id_vars=['fold', 'epoch'], var_name='metric', value_name='value'\n",
    ")\n",
    "metrics_data['metric'] = metrics_data['metric'].str.replace('overall_macro_', '').str.capitalize()\n",
    "metrics_data['fold_epoch'] = 'F' + metrics_data['fold'].astype(str) + ':E' + metrics_data['epoch'].astype(str)\n",
    "\n",
    "heatmap = alt.Chart(metrics_data).mark_rect().encode(\n",
    "    x='fold_epoch:O', y='metric:N',\n",
    "    color=alt.Color('value:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    tooltip=['fold_epoch:N', 'metric:N', alt.Tooltip('value:Q', format='.4f')]\n",
    ").properties(width=700, height=150, title='Precision/Recall/F1 Heatmap')\n",
    "\n",
    "heatmap.save(os.path.join(figures_root, 'fold_vs_epoch_augmented.svg'))\n",
    "os.path.join(figures_root, 'fold_vs_epoch_augmented.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f99d57-d61d-4de7-974a-32f713900f1d",
   "metadata": {},
   "source": [
    "![](../figures/fold_vs_epoch_augmented.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc78d09-d9fb-4175-8e4a-ac9661373cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipride",
   "language": "python",
   "name": "multipride"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
