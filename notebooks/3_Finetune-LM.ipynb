{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b4c6172-46ad-4e4f-8957-9eca338ebceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All random seeds set to 42\n",
      "training files: ['train_es.csv', 'train_en.csv', 'train_it.csv']\n",
      "Total training samples: 2988\n",
      "================================================================================\n",
      "CLASS DISTRIBUTION\n",
      "================================================================================\n",
      "\n",
      "Overall:\n",
      "  Class 0 (NOT_RECLAMATORY): 2560 (85.7%)\n",
      "  Class 1 (RECLAMATORY): 428 (14.3%)\n",
      "  Total: 2988\n",
      "\n",
      "Per Language:\n",
      "  EN: Class 0=938, Class 1=88, Total=1026\n",
      "  ES: Class 0=743, Class 1=133, Total=876\n",
      "  IT: Class 0=879, Class 1=207, Total=1086\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "from src.baseline.baseline import train_df, figures_root\n",
    "from src.finetune.finetuner import main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50555366-5e60-4daa-a97c-7058a8315547",
   "metadata": {},
   "source": [
    "# Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093cade9-d5cf-461f-8c38-7d0114cd7408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training would be start on the device: cuda\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration for fine-tuning\"\"\"\n",
    "\n",
    "    # Model configuration\n",
    "    MODEL_NAME = \"cardiffnlp/twitter-xlm-roberta-base\"  # Base model\n",
    "    NUM_LABELS = 2  # Binary classification\n",
    "    MAX_LENGTH = 128  # Maximum sequence length\n",
    "    NUM_FROZEN_LAYERS = 6  # Number of initial layers to freeze (0 = only train classification head)\n",
    "\n",
    "    # Training configuration\n",
    "    LEARNING_RATE = 5e-6\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    NUM_EPOCHS = 10\n",
    "    BATCH_SIZE = 4\n",
    "    GRADIENT_ACCUMULATION_STEPS = 4\n",
    "    WARMUP_RATIO = 0.05  # Warmup as % of total steps\n",
    "\n",
    "    # Early stopping\n",
    "    PATIENCE = 3\n",
    "    EVAL_STRATEGY = \"epoch\"  # Evaluate at end of each epoch\n",
    "\n",
    "    # Cross-validation\n",
    "    N_SPLITS = 5\n",
    "    TRAIN_RATIO = 0.8  # 80% for training from each fold\n",
    "    VAL_RATIO = 0.2  # 20% for validation from each fold\n",
    "\n",
    "    # Dynamic undersampling\n",
    "    DYNAMIC_UNDERSAMPLE = True  # Balance classes per epoch\n",
    "\n",
    "    # Model saving\n",
    "    MAX_MODELS_TO_SAVE = 2\n",
    "    OUTPUT_DIR = \"../fine_tuned_models\"\n",
    "    RESULTS_DIR = \"../results/roberta-fine-tune/\"\n",
    "\n",
    "    # Device\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training would be start on the device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb85403e-856b-4c4c-b82d-ee24fc3b5533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 08:22:09,852 - INFO - ================================================================================\n",
      "2025-11-12 08:22:09,852 - INFO - Starting Fine-tuning Pipeline\n",
      "2025-11-12 08:22:09,852 - INFO - ================================================================================\n",
      "2025-11-12 08:22:09,857 - INFO - Fold 0: Train=1912, Val=478\n",
      "2025-11-12 08:22:09,858 - INFO -   Train label dist: {0: 1638, 1: 274}\n",
      "2025-11-12 08:22:09,858 - INFO -   Train lang dist: {'it': 696, 'en': 656, 'es': 560}\n",
      "2025-11-12 08:22:09,860 - INFO - Fold 1: Train=1912, Val=478\n",
      "2025-11-12 08:22:09,861 - INFO -   Train label dist: {0: 1639, 1: 273}\n",
      "2025-11-12 08:22:09,861 - INFO -   Train lang dist: {'it': 696, 'en': 656, 'es': 560}\n",
      "2025-11-12 08:22:09,864 - INFO - Fold 2: Train=1912, Val=478\n",
      "2025-11-12 08:22:09,864 - INFO -   Train label dist: {0: 1638, 1: 274}\n",
      "2025-11-12 08:22:09,864 - INFO -   Train lang dist: {'it': 695, 'en': 657, 'es': 560}\n",
      "2025-11-12 08:22:09,867 - INFO - Fold 3: Train=1912, Val=479\n",
      "2025-11-12 08:22:09,867 - INFO -   Train label dist: {0: 1639, 1: 273}\n",
      "2025-11-12 08:22:09,867 - INFO -   Train lang dist: {'it': 695, 'en': 657, 'es': 560}\n",
      "2025-11-12 08:22:09,869 - INFO - Fold 4: Train=1912, Val=479\n",
      "2025-11-12 08:22:09,870 - INFO -   Train label dist: {0: 1640, 1: 272}\n",
      "2025-11-12 08:22:09,870 - INFO -   Train lang dist: {'it': 695, 'en': 657, 'es': 560}\n",
      "2025-11-12 08:22:09,871 - INFO - \n",
      "================================================================================\n",
      "2025-11-12 08:22:09,871 - INFO - Fold 1/5\n",
      "2025-11-12 08:22:09,871 - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 0:\n",
      "  Train: 274 positive samples\n",
      "  Val:   68 positive samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-11-12 08:22:13,133 - INFO - Froze: Embeddings + First 6 Encoder Layers\n",
      "2025-11-12 08:22:13,133 - INFO - Trainable: Classification Head + Remaining Encoder Layers\n",
      "2025-11-12 08:22:13,134 - INFO - Trainable parameters: 43,119,362 / 278,045,186 (15.51%)\n",
      "2025-11-12 08:22:13,135 - INFO - Label weights: {0: 0.5836385836385837, 1: 3.489051094890511}\n",
      "2025-11-12 08:22:13,135 - INFO - Language weights: {'it': 0.9080362792659776, 'en': 0.9634043450748787, 'es': 1.1285593756591437}\n",
      "2025-11-12 08:22:13,135 - INFO - Pos weight (for BCE): 5.9781\n",
      "2025-11-12 08:22:13,136 - INFO - \n",
      "Epoch 1/10\n",
      "2025-11-12 08:22:13,137 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 53.85it/s, loss=0.334]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 160.67it/s]\n",
      "2025-11-12 08:22:16,439 - INFO - Train Loss: 0.3267\n",
      "2025-11-12 08:22:16,440 - INFO - Val Loss: 0.1151\n",
      "2025-11-12 08:22:16,440 - INFO - Overall - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-12 08:22:16,440 - INFO - en - Precision: 0.4576, Recall: 0.5000, F1: 0.4778\n",
      "2025-11-12 08:22:16,440 - INFO - es - Precision: 0.4250, Recall: 0.5000, F1: 0.4595\n",
      "2025-11-12 08:22:16,440 - INFO - it - Precision: 0.4046, Recall: 0.5000, F1: 0.4473\n",
      "2025-11-12 08:22:17,082 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_0_f1_0.4617.pt (F1: 0.4617, Fold: 0, Epoch: 0)\n",
      "2025-11-12 08:22:17,082 - INFO - \n",
      "Epoch 2/10\n",
      "2025-11-12 08:22:17,083 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 57.76it/s, loss=0.318]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.99it/s]\n",
      "2025-11-12 08:22:20,207 - INFO - Train Loss: 0.3086\n",
      "2025-11-12 08:22:20,208 - INFO - Val Loss: 0.1100\n",
      "2025-11-12 08:22:20,208 - INFO - Overall - Precision: 0.4289, Recall: 0.5000, F1: 0.4617\n",
      "2025-11-12 08:22:20,208 - INFO - en - Precision: 0.4576, Recall: 0.5000, F1: 0.4778\n",
      "2025-11-12 08:22:20,208 - INFO - es - Precision: 0.4250, Recall: 0.5000, F1: 0.4595\n",
      "2025-11-12 08:22:20,208 - INFO - it - Precision: 0.4046, Recall: 0.5000, F1: 0.4473\n",
      "2025-11-12 08:22:20,208 - INFO - \n",
      "Epoch 3/10\n",
      "2025-11-12 08:22:20,209 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 57.94it/s, loss=0.259]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 162.41it/s]\n",
      "2025-11-12 08:22:23,323 - INFO - Train Loss: 0.2519\n",
      "2025-11-12 08:22:23,323 - INFO - Val Loss: 0.1252\n",
      "2025-11-12 08:22:23,324 - INFO - Overall - Precision: 0.5305, Recall: 0.5124, F1: 0.5057\n",
      "2025-11-12 08:22:23,324 - INFO - en - Precision: 0.4576, Recall: 0.5000, F1: 0.4778\n",
      "2025-11-12 08:22:23,324 - INFO - es - Precision: 0.6828, Recall: 0.5588, F1: 0.5696\n",
      "2025-11-12 08:22:23,324 - INFO - it - Precision: 0.4520, Recall: 0.4696, F1: 0.4568\n",
      "2025-11-12 08:22:23,957 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_2_f1_0.5057.pt (F1: 0.5057, Fold: 0, Epoch: 2)\n",
      "2025-11-12 08:22:23,957 - INFO - \n",
      "Epoch 4/10\n",
      "2025-11-12 08:22:23,958 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 57.91it/s, loss=0.244]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 164.51it/s]\n",
      "2025-11-12 08:22:27,064 - INFO - Train Loss: 0.2367\n",
      "2025-11-12 08:22:27,065 - INFO - Val Loss: 0.1335\n",
      "2025-11-12 08:22:27,065 - INFO - Overall - Precision: 0.5975, Recall: 0.6057, F1: 0.6012\n",
      "2025-11-12 08:22:27,065 - INFO - en - Precision: 0.9604, Recall: 0.5357, F1: 0.5460\n",
      "2025-11-12 08:22:27,065 - INFO - es - Precision: 0.6537, Recall: 0.6597, F1: 0.6566\n",
      "2025-11-12 08:22:27,065 - INFO - it - Precision: 0.5424, Recall: 0.5577, F1: 0.5399\n",
      "2025-11-12 08:22:27,129 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_0_f1_0.4617.pt\n",
      "2025-11-12 08:22:27,784 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_3_f1_0.6012.pt (F1: 0.6012, Fold: 0, Epoch: 3)\n",
      "2025-11-12 08:22:27,785 - INFO - \n",
      "Epoch 5/10\n",
      "2025-11-12 08:22:27,786 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.15it/s, loss=0.217]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.22it/s]\n",
      "2025-11-12 08:22:30,897 - INFO - Train Loss: 0.2107\n",
      "2025-11-12 08:22:30,898 - INFO - Val Loss: 0.1369\n",
      "2025-11-12 08:22:30,898 - INFO - Overall - Precision: 0.6024, Recall: 0.6524, F1: 0.6132\n",
      "2025-11-12 08:22:30,898 - INFO - en - Precision: 0.9604, Recall: 0.5357, F1: 0.5460\n",
      "2025-11-12 08:22:30,898 - INFO - es - Precision: 0.6146, Recall: 0.6653, F1: 0.6267\n",
      "2025-11-12 08:22:30,898 - INFO - it - Precision: 0.5807, Recall: 0.6298, F1: 0.5511\n",
      "2025-11-12 08:22:30,961 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_2_f1_0.5057.pt\n",
      "2025-11-12 08:22:31,594 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_4_f1_0.6132.pt (F1: 0.6132, Fold: 0, Epoch: 4)\n",
      "2025-11-12 08:22:31,594 - INFO - \n",
      "Epoch 6/10\n",
      "2025-11-12 08:22:31,595 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.04it/s, loss=0.202]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.86it/s]\n",
      "2025-11-12 08:22:34,700 - INFO - Train Loss: 0.1961\n",
      "2025-11-12 08:22:34,700 - INFO - Val Loss: 0.1525\n",
      "2025-11-12 08:22:34,700 - INFO - Overall - Precision: 0.6025, Recall: 0.6882, F1: 0.5992\n",
      "2025-11-12 08:22:34,700 - INFO - en - Precision: 0.6265, Recall: 0.5291, F1: 0.5349\n",
      "2025-11-12 08:22:34,700 - INFO - es - Precision: 0.6435, Recall: 0.7395, F1: 0.6557\n",
      "2025-11-12 08:22:34,701 - INFO - it - Precision: 0.5899, Recall: 0.6287, F1: 0.4637\n",
      "2025-11-12 08:22:34,701 - INFO - \n",
      "Epoch 7/10\n",
      "2025-11-12 08:22:34,701 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 57.73it/s, loss=0.197]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.87it/s]\n",
      "2025-11-12 08:22:37,818 - INFO - Train Loss: 0.1917\n",
      "2025-11-12 08:22:37,818 - INFO - Val Loss: 0.1503\n",
      "2025-11-12 08:22:37,818 - INFO - Overall - Precision: 0.6345, Recall: 0.7223, F1: 0.6485\n",
      "2025-11-12 08:22:37,818 - INFO - en - Precision: 0.5846, Recall: 0.5258, F1: 0.5299\n",
      "2025-11-12 08:22:37,818 - INFO - es - Precision: 0.6074, Recall: 0.7045, F1: 0.5856\n",
      "2025-11-12 08:22:37,818 - INFO - it - Precision: 0.6697, Recall: 0.7671, F1: 0.6650\n",
      "2025-11-12 08:22:37,885 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_3_f1_0.6012.pt\n",
      "2025-11-12 08:22:38,532 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_6_f1_0.6485.pt (F1: 0.6485, Fold: 0, Epoch: 6)\n",
      "2025-11-12 08:22:38,532 - INFO - \n",
      "Epoch 8/10\n",
      "2025-11-12 08:22:38,534 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 57.94it/s, loss=0.186]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.42it/s]\n",
      "2025-11-12 08:22:41,644 - INFO - Train Loss: 0.1805\n",
      "2025-11-12 08:22:41,644 - INFO - Val Loss: 0.1404\n",
      "2025-11-12 08:22:41,644 - INFO - Overall - Precision: 0.6675, Recall: 0.7664, F1: 0.6896\n",
      "2025-11-12 08:22:41,644 - INFO - en - Precision: 0.5726, Recall: 0.5482, F1: 0.5560\n",
      "2025-11-12 08:22:41,645 - INFO - es - Precision: 0.6250, Recall: 0.7367, F1: 0.6090\n",
      "2025-11-12 08:22:41,645 - INFO - it - Precision: 0.7367, Recall: 0.8474, F1: 0.7574\n",
      "2025-11-12 08:22:41,709 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_4_f1_0.6132.pt\n",
      "2025-11-12 08:22:42,345 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_7_f1_0.6896.pt (F1: 0.6896, Fold: 0, Epoch: 7)\n",
      "2025-11-12 08:22:42,345 - INFO - \n",
      "Epoch 9/10\n",
      "2025-11-12 08:22:42,346 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.14it/s, loss=0.191]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.64it/s]\n",
      "2025-11-12 08:22:45,447 - INFO - Train Loss: 0.1856\n",
      "2025-11-12 08:22:45,447 - INFO - Val Loss: 0.1021\n",
      "2025-11-12 08:22:45,447 - INFO - Overall - Precision: 0.7012, Recall: 0.7343, F1: 0.7153\n",
      "2025-11-12 08:22:45,447 - INFO - en - Precision: 0.4573, Recall: 0.4967, F1: 0.4762\n",
      "2025-11-12 08:22:45,448 - INFO - es - Precision: 0.6534, Recall: 0.7213, F1: 0.6719\n",
      "2025-11-12 08:22:45,448 - INFO - it - Precision: 0.7488, Recall: 0.8189, F1: 0.7724\n",
      "2025-11-12 08:22:45,512 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_6_f1_0.6485.pt\n",
      "2025-11-12 08:22:46,151 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_8_f1_0.7153.pt (F1: 0.7153, Fold: 0, Epoch: 8)\n",
      "2025-11-12 08:22:46,151 - INFO - \n",
      "Epoch 10/10\n",
      "2025-11-12 08:22:46,152 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.00it/s, loss=0.182]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 164.26it/s]\n",
      "2025-11-12 08:22:49,256 - INFO - Train Loss: 0.1770\n",
      "2025-11-12 08:22:49,256 - INFO - Val Loss: 0.1271\n",
      "2025-11-12 08:22:49,256 - INFO - Overall - Precision: 0.6948, Recall: 0.7847, F1: 0.7216\n",
      "2025-11-12 08:22:49,256 - INFO - en - Precision: 0.6210, Recall: 0.6131, F1: 0.6168\n",
      "2025-11-12 08:22:49,256 - INFO - es - Precision: 0.6699, Recall: 0.7759, F1: 0.6893\n",
      "2025-11-12 08:22:49,256 - INFO - it - Precision: 0.7371, Recall: 0.8394, F1: 0.7597\n",
      "2025-11-12 08:22:49,320 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_7_f1_0.6896.pt\n",
      "2025-11-12 08:22:49,978 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_9_f1_0.7216.pt (F1: 0.7216, Fold: 0, Epoch: 9)\n",
      "2025-11-12 08:22:49,978 - INFO - \n",
      "================================================================================\n",
      "2025-11-12 08:22:49,978 - INFO - Fold 2/5\n",
      "2025-11-12 08:22:49,978 - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 1:\n",
      "  Train: 273 positive samples\n",
      "  Val:   69 positive samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-11-12 08:22:52,973 - INFO - Froze: Embeddings + First 6 Encoder Layers\n",
      "2025-11-12 08:22:52,973 - INFO - Trainable: Classification Head + Remaining Encoder Layers\n",
      "2025-11-12 08:22:52,974 - INFO - Trainable parameters: 43,119,362 / 278,045,186 (15.51%)\n",
      "2025-11-12 08:22:52,975 - INFO - Label weights: {0: 0.5832824893227577, 1: 3.501831501831502}\n",
      "2025-11-12 08:22:52,975 - INFO - Language weights: {'it': 0.9080362792659776, 'en': 0.9634043450748787, 'es': 1.1285593756591437}\n",
      "2025-11-12 08:22:52,975 - INFO - Pos weight (for BCE): 6.0037\n",
      "2025-11-12 08:22:52,976 - INFO - \n",
      "Epoch 1/10\n",
      "2025-11-12 08:22:52,977 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 57.97it/s, loss=0.351]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 164.44it/s]\n",
      "2025-11-12 08:22:56,090 - INFO - Train Loss: 0.3410\n",
      "2025-11-12 08:22:56,090 - INFO - Val Loss: 0.1158\n",
      "2025-11-12 08:22:56,090 - INFO - Overall - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-12 08:22:56,090 - INFO - en - Precision: 0.4573, Recall: 0.5000, F1: 0.4777\n",
      "2025-11-12 08:22:56,090 - INFO - es - Precision: 0.4220, Recall: 0.5000, F1: 0.4577\n",
      "2025-11-12 08:22:56,090 - INFO - it - Precision: 0.4046, Recall: 0.5000, F1: 0.4473\n",
      "2025-11-12 08:22:56,097 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_0_f1_0.4611.pt\n",
      "2025-11-12 08:22:56,748 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_0_f1_0.4611.pt (F1: 0.4611, Fold: 1, Epoch: 0)\n",
      "2025-11-12 08:22:56,749 - INFO - \n",
      "Epoch 2/10\n",
      "2025-11-12 08:22:56,750 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 57.80it/s, loss=0.288]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.77it/s]\n",
      "2025-11-12 08:22:59,873 - INFO - Train Loss: 0.2798\n",
      "2025-11-12 08:22:59,873 - INFO - Val Loss: 0.1119\n",
      "2025-11-12 08:22:59,873 - INFO - Overall - Precision: 0.6786, Recall: 0.5060, F1: 0.4751\n",
      "2025-11-12 08:22:59,874 - INFO - en - Precision: 0.4573, Recall: 0.5000, F1: 0.4777\n",
      "2025-11-12 08:22:59,874 - INFO - es - Precision: 0.4220, Recall: 0.5000, F1: 0.4577\n",
      "2025-11-12 08:22:59,874 - INFO - it - Precision: 0.6564, Recall: 0.5116, F1: 0.4755\n",
      "2025-11-12 08:22:59,880 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_1_f1_0.4751.pt\n",
      "2025-11-12 08:23:00,532 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_1_f1_0.4751.pt (F1: 0.4751, Fold: 1, Epoch: 1)\n",
      "2025-11-12 08:23:00,532 - INFO - \n",
      "Epoch 3/10\n",
      "2025-11-12 08:23:00,533 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 57.87it/s, loss=0.263]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.44it/s]\n",
      "2025-11-12 08:23:03,656 - INFO - Train Loss: 0.2554\n",
      "2025-11-12 08:23:03,656 - INFO - Val Loss: 0.1343\n",
      "2025-11-12 08:23:03,656 - INFO - Overall - Precision: 0.5689, Recall: 0.5359, F1: 0.5391\n",
      "2025-11-12 08:23:03,656 - INFO - en - Precision: 0.4565, Recall: 0.4900, F1: 0.4727\n",
      "2025-11-12 08:23:03,656 - INFO - es - Precision: 0.6823, Recall: 0.5741, F1: 0.5897\n",
      "2025-11-12 08:23:03,657 - INFO - it - Precision: 0.5209, Recall: 0.5150, F1: 0.5136\n",
      "2025-11-12 08:23:03,663 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_2_f1_0.5391.pt\n",
      "2025-11-12 08:23:04,312 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_2_f1_0.5391.pt (F1: 0.5391, Fold: 1, Epoch: 2)\n",
      "2025-11-12 08:23:04,313 - INFO - \n",
      "Epoch 4/10\n",
      "2025-11-12 08:23:04,314 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 57.94it/s, loss=0.231]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 162.61it/s]\n",
      "2025-11-12 08:23:07,428 - INFO - Train Loss: 0.2245\n",
      "2025-11-12 08:23:07,428 - INFO - Val Loss: 0.1475\n",
      "2025-11-12 08:23:07,428 - INFO - Overall - Precision: 0.5654, Recall: 0.5882, F1: 0.5707\n",
      "2025-11-12 08:23:07,428 - INFO - en - Precision: 0.4562, Recall: 0.4867, F1: 0.4710\n",
      "2025-11-12 08:23:07,428 - INFO - es - Precision: 0.6093, Recall: 0.6736, F1: 0.6160\n",
      "2025-11-12 08:23:07,429 - INFO - it - Precision: 0.5201, Recall: 0.5282, F1: 0.5123\n",
      "2025-11-12 08:23:07,435 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_3_f1_0.5707.pt\n",
      "2025-11-12 08:23:08,087 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_3_f1_0.5707.pt (F1: 0.5707, Fold: 1, Epoch: 3)\n",
      "2025-11-12 08:23:08,087 - INFO - \n",
      "Epoch 5/10\n",
      "2025-11-12 08:23:08,089 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.32it/s, loss=0.211]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 162.72it/s]\n",
      "2025-11-12 08:23:11,187 - INFO - Train Loss: 0.2068\n",
      "2025-11-12 08:23:11,187 - INFO - Val Loss: 0.1658\n",
      "2025-11-12 08:23:11,187 - INFO - Overall - Precision: 0.6034, Recall: 0.6961, F1: 0.5916\n",
      "2025-11-12 08:23:11,187 - INFO - en - Precision: 0.4562, Recall: 0.4867, F1: 0.4710\n",
      "2025-11-12 08:23:11,187 - INFO - es - Precision: 0.6310, Recall: 0.7487, F1: 0.5863\n",
      "2025-11-12 08:23:11,187 - INFO - it - Precision: 0.6069, Recall: 0.6644, F1: 0.5130\n",
      "2025-11-12 08:23:11,194 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_4_f1_0.5916.pt\n",
      "2025-11-12 08:23:11,837 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_4_f1_0.5916.pt (F1: 0.5916, Fold: 1, Epoch: 4)\n",
      "2025-11-12 08:23:11,837 - INFO - \n",
      "Epoch 6/10\n",
      "2025-11-12 08:23:11,838 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 59.48it/s, loss=0.202]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 162.96it/s]\n",
      "2025-11-12 08:23:14,889 - INFO - Train Loss: 0.1942\n",
      "2025-11-12 08:23:14,889 - INFO - Val Loss: 0.1444\n",
      "2025-11-12 08:23:14,889 - INFO - Overall - Precision: 0.6304, Recall: 0.7148, F1: 0.6429\n",
      "2025-11-12 08:23:14,889 - INFO - en - Precision: 0.4568, Recall: 0.4933, F1: 0.4744\n",
      "2025-11-12 08:23:14,889 - INFO - es - Precision: 0.6341, Recall: 0.7452, F1: 0.6219\n",
      "2025-11-12 08:23:14,889 - INFO - it - Precision: 0.6441, Recall: 0.7305, F1: 0.6268\n",
      "2025-11-12 08:23:14,896 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_5_f1_0.6429.pt\n",
      "2025-11-12 08:23:15,539 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_5_f1_0.6429.pt (F1: 0.6429, Fold: 1, Epoch: 5)\n",
      "2025-11-12 08:23:15,540 - INFO - \n",
      "Epoch 7/10\n",
      "2025-11-12 08:23:15,541 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.91it/s, loss=0.181]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.41it/s]\n",
      "2025-11-12 08:23:18,621 - INFO - Train Loss: 0.1795\n",
      "2025-11-12 08:23:18,621 - INFO - Val Loss: 0.1521\n",
      "2025-11-12 08:23:18,621 - INFO - Overall - Precision: 0.6560, Recall: 0.7488, F1: 0.6751\n",
      "2025-11-12 08:23:18,621 - INFO - en - Precision: 0.4568, Recall: 0.4933, F1: 0.4744\n",
      "2025-11-12 08:23:18,622 - INFO - es - Precision: 0.6407, Recall: 0.7672, F1: 0.5909\n",
      "2025-11-12 08:23:18,622 - INFO - it - Precision: 0.7154, Recall: 0.8055, F1: 0.7353\n",
      "2025-11-12 08:23:18,628 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_6_f1_0.6751.pt\n",
      "2025-11-12 08:23:19,274 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_6_f1_0.6751.pt (F1: 0.6751, Fold: 1, Epoch: 6)\n",
      "2025-11-12 08:23:19,275 - INFO - \n",
      "Epoch 8/10\n",
      "2025-11-12 08:23:19,275 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 59.25it/s, loss=0.169]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 162.16it/s]\n",
      "2025-11-12 08:23:22,339 - INFO - Train Loss: 0.1657\n",
      "2025-11-12 08:23:22,339 - INFO - Val Loss: 0.1832\n",
      "2025-11-12 08:23:22,339 - INFO - Overall - Precision: 0.6518, Recall: 0.7535, F1: 0.6682\n",
      "2025-11-12 08:23:22,339 - INFO - en - Precision: 0.4557, Recall: 0.4800, F1: 0.4675\n",
      "2025-11-12 08:23:22,339 - INFO - es - Precision: 0.6344, Recall: 0.7546, F1: 0.5736\n",
      "2025-11-12 08:23:22,340 - INFO - it - Precision: 0.7282, Recall: 0.8323, F1: 0.7483\n",
      "2025-11-12 08:23:22,340 - INFO - \n",
      "Epoch 9/10\n",
      "2025-11-12 08:23:22,341 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 59.17it/s, loss=0.172]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.25it/s]\n",
      "2025-11-12 08:23:25,402 - INFO - Train Loss: 0.1707\n",
      "2025-11-12 08:23:25,403 - INFO - Val Loss: 0.1631\n",
      "2025-11-12 08:23:25,403 - INFO - Overall - Precision: 0.6635, Recall: 0.7633, F1: 0.6839\n",
      "2025-11-12 08:23:25,403 - INFO - en - Precision: 0.4557, Recall: 0.4800, F1: 0.4675\n",
      "2025-11-12 08:23:25,403 - INFO - es - Precision: 0.6524, Recall: 0.7882, F1: 0.6201\n",
      "2025-11-12 08:23:25,403 - INFO - it - Precision: 0.7282, Recall: 0.8323, F1: 0.7483\n",
      "2025-11-12 08:23:25,410 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_8_f1_0.6839.pt\n",
      "2025-11-12 08:23:26,063 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_8_f1_0.6839.pt (F1: 0.6839, Fold: 1, Epoch: 8)\n",
      "2025-11-12 08:23:26,064 - INFO - \n",
      "Epoch 10/10\n",
      "2025-11-12 08:23:26,065 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 59.78it/s, loss=0.177]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 162.84it/s]\n",
      "2025-11-12 08:23:29,105 - INFO - Train Loss: 0.1749\n",
      "2025-11-12 08:23:29,105 - INFO - Val Loss: 0.1643\n",
      "2025-11-12 08:23:29,105 - INFO - Overall - Precision: 0.6682, Recall: 0.7670, F1: 0.6899\n",
      "2025-11-12 08:23:29,105 - INFO - en - Precision: 0.4539, Recall: 0.4600, F1: 0.4570\n",
      "2025-11-12 08:23:29,105 - INFO - es - Precision: 0.6576, Recall: 0.7966, F1: 0.6319\n",
      "2025-11-12 08:23:29,106 - INFO - it - Precision: 0.7623, Recall: 0.8573, F1: 0.7895\n",
      "2025-11-12 08:23:29,124 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_9_f1_0.6899.pt\n",
      "2025-11-12 08:23:29,763 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_1_epoch_9_f1_0.6899.pt (F1: 0.6899, Fold: 1, Epoch: 9)\n",
      "2025-11-12 08:23:29,763 - INFO - \n",
      "================================================================================\n",
      "2025-11-12 08:23:29,764 - INFO - Fold 3/5\n",
      "2025-11-12 08:23:29,764 - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 2:\n",
      "  Train: 274 positive samples\n",
      "  Val:   69 positive samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-11-12 08:23:32,714 - INFO - Froze: Embeddings + First 6 Encoder Layers\n",
      "2025-11-12 08:23:32,715 - INFO - Trainable: Classification Head + Remaining Encoder Layers\n",
      "2025-11-12 08:23:32,715 - INFO - Trainable parameters: 43,119,362 / 278,045,186 (15.51%)\n",
      "2025-11-12 08:23:32,716 - INFO - Label weights: {0: 0.5836385836385837, 1: 3.489051094890511}\n",
      "2025-11-12 08:23:32,717 - INFO - Language weights: {'it': 0.9093912592122662, 'en': 0.961989231586796, 'es': 1.1286195092009375}\n",
      "2025-11-12 08:23:32,717 - INFO - Pos weight (for BCE): 5.9781\n",
      "2025-11-12 08:23:32,718 - INFO - \n",
      "Epoch 1/10\n",
      "2025-11-12 08:23:32,719 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.71it/s, loss=0.336]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.33it/s]\n",
      "2025-11-12 08:23:35,816 - INFO - Train Loss: 0.3337\n",
      "2025-11-12 08:23:35,816 - INFO - Val Loss: 0.1138\n",
      "2025-11-12 08:23:35,816 - INFO - Overall - Precision: 0.4278, Recall: 0.5000, F1: 0.4611\n",
      "2025-11-12 08:23:35,817 - INFO - en - Precision: 0.4573, Recall: 0.5000, F1: 0.4777\n",
      "2025-11-12 08:23:35,817 - INFO - es - Precision: 0.4220, Recall: 0.5000, F1: 0.4577\n",
      "2025-11-12 08:23:35,817 - INFO - it - Precision: 0.4046, Recall: 0.5000, F1: 0.4473\n",
      "2025-11-12 08:23:35,849 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_0_f1_0.4611.pt\n",
      "2025-11-12 08:23:36,508 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_0_f1_0.4611.pt (F1: 0.4611, Fold: 2, Epoch: 0)\n",
      "2025-11-12 08:23:36,508 - INFO - \n",
      "Epoch 2/10\n",
      "2025-11-12 08:23:36,509 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.74it/s, loss=0.323]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.44it/s]\n",
      "2025-11-12 08:23:39,596 - INFO - Train Loss: 0.3156\n",
      "2025-11-12 08:23:39,596 - INFO - Val Loss: 0.1096\n",
      "2025-11-12 08:23:39,597 - INFO - Overall - Precision: 0.4275, Recall: 0.4976, F1: 0.4599\n",
      "2025-11-12 08:23:39,597 - INFO - en - Precision: 0.4573, Recall: 0.5000, F1: 0.4777\n",
      "2025-11-12 08:23:39,597 - INFO - es - Precision: 0.4220, Recall: 0.5000, F1: 0.4577\n",
      "2025-11-12 08:23:39,597 - INFO - it - Precision: 0.4035, Recall: 0.4929, F1: 0.4437\n",
      "2025-11-12 08:23:39,597 - INFO - \n",
      "Epoch 3/10\n",
      "2025-11-12 08:23:39,598 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.89it/s, loss=0.251]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.09it/s]\n",
      "2025-11-12 08:23:42,681 - INFO - Train Loss: 0.2435\n",
      "2025-11-12 08:23:42,681 - INFO - Val Loss: 0.1312\n",
      "2025-11-12 08:23:42,681 - INFO - Overall - Precision: 0.5849, Recall: 0.5527, F1: 0.5599\n",
      "2025-11-12 08:23:42,681 - INFO - en - Precision: 0.4568, Recall: 0.4933, F1: 0.4744\n",
      "2025-11-12 08:23:42,682 - INFO - es - Precision: 0.6796, Recall: 0.5556, F1: 0.5638\n",
      "2025-11-12 08:23:42,682 - INFO - it - Precision: 0.5555, Recall: 0.5542, F1: 0.5548\n",
      "2025-11-12 08:23:42,688 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_2_f1_0.5599.pt\n",
      "2025-11-12 08:23:43,328 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_2_f1_0.5599.pt (F1: 0.5599, Fold: 2, Epoch: 2)\n",
      "2025-11-12 08:23:43,328 - INFO - \n",
      "Epoch 4/10\n",
      "2025-11-12 08:23:43,329 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.53it/s, loss=0.244]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.65it/s]\n",
      "2025-11-12 08:23:46,414 - INFO - Train Loss: 0.2368\n",
      "2025-11-12 08:23:46,415 - INFO - Val Loss: 0.1477\n",
      "2025-11-12 08:23:46,415 - INFO - Overall - Precision: 0.5595, Recall: 0.5881, F1: 0.5625\n",
      "2025-11-12 08:23:46,415 - INFO - en - Precision: 0.4568, Recall: 0.4933, F1: 0.4744\n",
      "2025-11-12 08:23:46,415 - INFO - es - Precision: 0.5817, Recall: 0.5877, F1: 0.5844\n",
      "2025-11-12 08:23:46,415 - INFO - it - Precision: 0.5350, Recall: 0.5566, F1: 0.4809\n",
      "2025-11-12 08:23:46,422 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_3_f1_0.5625.pt\n",
      "2025-11-12 08:23:47,061 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_3_f1_0.5625.pt (F1: 0.5625, Fold: 2, Epoch: 3)\n",
      "2025-11-12 08:23:47,062 - INFO - \n",
      "Epoch 5/10\n",
      "2025-11-12 08:23:47,063 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 59.19it/s, loss=0.221]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 162.63it/s]\n",
      "2025-11-12 08:23:50,126 - INFO - Train Loss: 0.2199\n",
      "2025-11-12 08:23:50,127 - INFO - Val Loss: 0.1436\n",
      "2025-11-12 08:23:50,127 - INFO - Overall - Precision: 0.6121, Recall: 0.6763, F1: 0.6231\n",
      "2025-11-12 08:23:50,127 - INFO - en - Precision: 0.4568, Recall: 0.4933, F1: 0.4744\n",
      "2025-11-12 08:23:50,127 - INFO - es - Precision: 0.5976, Recall: 0.6610, F1: 0.5987\n",
      "2025-11-12 08:23:50,127 - INFO - it - Precision: 0.6273, Recall: 0.7047, F1: 0.6039\n",
      "2025-11-12 08:23:50,134 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_4_f1_0.6231.pt\n",
      "2025-11-12 08:23:50,794 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_4_f1_0.6231.pt (F1: 0.6231, Fold: 2, Epoch: 4)\n",
      "2025-11-12 08:23:50,795 - INFO - \n",
      "Epoch 6/10\n",
      "2025-11-12 08:23:50,796 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 59.24it/s, loss=0.192]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.89it/s]\n",
      "2025-11-12 08:23:53,852 - INFO - Train Loss: 0.1919\n",
      "2025-11-12 08:23:53,853 - INFO - Val Loss: 0.1569\n",
      "2025-11-12 08:23:53,853 - INFO - Overall - Precision: 0.6222, Recall: 0.7230, F1: 0.6226\n",
      "2025-11-12 08:23:53,853 - INFO - en - Precision: 0.4571, Recall: 0.4967, F1: 0.4760\n",
      "2025-11-12 08:23:53,853 - INFO - es - Precision: 0.6255, Recall: 0.7267, F1: 0.6159\n",
      "2025-11-12 08:23:53,853 - INFO - it - Precision: 0.6528, Recall: 0.7321, F1: 0.5511\n",
      "2025-11-12 08:23:53,853 - INFO - \n",
      "Epoch 7/10\n",
      "2025-11-12 08:23:53,854 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 57.78it/s, loss=0.185]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 162.57it/s]\n",
      "2025-11-12 08:23:56,975 - INFO - Train Loss: 0.1801\n",
      "2025-11-12 08:23:56,975 - INFO - Val Loss: 0.1558\n",
      "2025-11-12 08:23:56,975 - INFO - Overall - Precision: 0.6402, Recall: 0.7461, F1: 0.6498\n",
      "2025-11-12 08:23:56,975 - INFO - en - Precision: 0.4571, Recall: 0.4967, F1: 0.4760\n",
      "2025-11-12 08:23:56,975 - INFO - es - Precision: 0.6172, Recall: 0.7200, F1: 0.5874\n",
      "2025-11-12 08:23:56,975 - INFO - it - Precision: 0.6875, Recall: 0.8036, F1: 0.6505\n",
      "2025-11-12 08:23:56,982 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_6_f1_0.6498.pt\n",
      "2025-11-12 08:23:57,627 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_6_f1_0.6498.pt (F1: 0.6498, Fold: 2, Epoch: 6)\n",
      "2025-11-12 08:23:57,628 - INFO - \n",
      "Epoch 8/10\n",
      "2025-11-12 08:23:57,629 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 59.69it/s, loss=0.199]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 162.04it/s]\n",
      "2025-11-12 08:24:00,676 - INFO - Train Loss: 0.1915\n",
      "2025-11-12 08:24:00,676 - INFO - Val Loss: 0.1199\n",
      "2025-11-12 08:24:00,676 - INFO - Overall - Precision: 0.7035, Recall: 0.7746, F1: 0.7281\n",
      "2025-11-12 08:24:00,676 - INFO - en - Precision: 0.4571, Recall: 0.4967, F1: 0.4760\n",
      "2025-11-12 08:24:00,677 - INFO - es - Precision: 0.6423, Recall: 0.7376, F1: 0.6512\n",
      "2025-11-12 08:24:00,677 - INFO - it - Precision: 0.7786, Recall: 0.8876, F1: 0.8081\n",
      "2025-11-12 08:24:00,691 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_8_f1_0.7153.pt\n",
      "2025-11-12 08:24:01,545 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_7_f1_0.7281.pt (F1: 0.7281, Fold: 2, Epoch: 7)\n",
      "2025-11-12 08:24:01,545 - INFO - \n",
      "Epoch 9/10\n",
      "2025-11-12 08:24:01,547 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.91it/s, loss=0.182]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.31it/s]\n",
      "2025-11-12 08:24:04,619 - INFO - Train Loss: 0.1819\n",
      "2025-11-12 08:24:04,619 - INFO - Val Loss: 0.1202\n",
      "2025-11-12 08:24:04,619 - INFO - Overall - Precision: 0.7108, Recall: 0.7782, F1: 0.7352\n",
      "2025-11-12 08:24:04,619 - INFO - en - Precision: 0.4571, Recall: 0.4967, F1: 0.4760\n",
      "2025-11-12 08:24:04,619 - INFO - es - Precision: 0.6344, Recall: 0.7292, F1: 0.6389\n",
      "2025-11-12 08:24:04,620 - INFO - it - Precision: 0.8083, Recall: 0.9054, F1: 0.8402\n",
      "2025-11-12 08:24:04,626 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_0_epoch_9_f1_0.7216.pt\n",
      "2025-11-12 08:24:05,467 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_2_epoch_8_f1_0.7352.pt (F1: 0.7352, Fold: 2, Epoch: 8)\n",
      "2025-11-12 08:24:05,468 - INFO - \n",
      "Epoch 10/10\n",
      "2025-11-12 08:24:05,469 - INFO - Undersampling: Minority=274, Majority=548\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.51it/s, loss=0.171]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.86it/s]\n",
      "2025-11-12 08:24:08,564 - INFO - Train Loss: 0.1655\n",
      "2025-11-12 08:24:08,564 - INFO - Val Loss: 0.1316\n",
      "2025-11-12 08:24:08,564 - INFO - Overall - Precision: 0.6993, Recall: 0.7877, F1: 0.7262\n",
      "2025-11-12 08:24:08,565 - INFO - en - Precision: 0.5300, Recall: 0.5157, F1: 0.5167\n",
      "2025-11-12 08:24:08,565 - INFO - es - Precision: 0.6344, Recall: 0.7292, F1: 0.6389\n",
      "2025-11-12 08:24:08,565 - INFO - it - Precision: 0.7946, Recall: 0.9179, F1: 0.8260\n",
      "2025-11-12 08:24:08,565 - INFO - \n",
      "================================================================================\n",
      "2025-11-12 08:24:08,565 - INFO - Fold 4/5\n",
      "2025-11-12 08:24:08,566 - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 3:\n",
      "  Train: 273 positive samples\n",
      "  Val:   70 positive samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-11-12 08:24:11,552 - INFO - Froze: Embeddings + First 6 Encoder Layers\n",
      "2025-11-12 08:24:11,553 - INFO - Trainable: Classification Head + Remaining Encoder Layers\n",
      "2025-11-12 08:24:11,553 - INFO - Trainable parameters: 43,119,362 / 278,045,186 (15.51%)\n",
      "2025-11-12 08:24:11,554 - INFO - Label weights: {0: 0.5832824893227577, 1: 3.501831501831502}\n",
      "2025-11-12 08:24:11,554 - INFO - Language weights: {'it': 0.9093912592122662, 'en': 0.961989231586796, 'es': 1.1286195092009375}\n",
      "2025-11-12 08:24:11,555 - INFO - Pos weight (for BCE): 6.0037\n",
      "2025-11-12 08:24:11,556 - INFO - \n",
      "Epoch 1/10\n",
      "2025-11-12 08:24:11,556 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.54it/s, loss=0.344]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.37it/s]\n",
      "2025-11-12 08:24:14,651 - INFO - Train Loss: 0.3388\n",
      "2025-11-12 08:24:14,652 - INFO - Val Loss: 0.1175\n",
      "2025-11-12 08:24:14,652 - INFO - Overall - Precision: 0.4269, Recall: 0.5000, F1: 0.4606\n",
      "2025-11-12 08:24:14,652 - INFO - en - Precision: 0.4573, Recall: 0.5000, F1: 0.4777\n",
      "2025-11-12 08:24:14,652 - INFO - es - Precision: 0.4220, Recall: 0.5000, F1: 0.4577\n",
      "2025-11-12 08:24:14,652 - INFO - it - Precision: 0.4023, Recall: 0.5000, F1: 0.4459\n",
      "2025-11-12 08:24:14,672 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_0_f1_0.4606.pt\n",
      "2025-11-12 08:24:15,309 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_0_f1_0.4606.pt (F1: 0.4606, Fold: 3, Epoch: 0)\n",
      "2025-11-12 08:24:15,309 - INFO - \n",
      "Epoch 2/10\n",
      "2025-11-12 08:24:15,310 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 59.18it/s, loss=0.277]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.68it/s]\n",
      "2025-11-12 08:24:18,379 - INFO - Train Loss: 0.2765\n",
      "2025-11-12 08:24:18,379 - INFO - Val Loss: 0.1129\n",
      "2025-11-12 08:24:18,379 - INFO - Overall - Precision: 0.4269, Recall: 0.5000, F1: 0.4606\n",
      "2025-11-12 08:24:18,379 - INFO - en - Precision: 0.4573, Recall: 0.5000, F1: 0.4777\n",
      "2025-11-12 08:24:18,379 - INFO - es - Precision: 0.4220, Recall: 0.5000, F1: 0.4577\n",
      "2025-11-12 08:24:18,379 - INFO - it - Precision: 0.4023, Recall: 0.5000, F1: 0.4459\n",
      "2025-11-12 08:24:18,380 - INFO - \n",
      "Epoch 3/10\n",
      "2025-11-12 08:24:18,380 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 59.12it/s, loss=0.253]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.97it/s]\n",
      "2025-11-12 08:24:21,450 - INFO - Train Loss: 0.2489\n",
      "2025-11-12 08:24:21,450 - INFO - Val Loss: 0.1336\n",
      "2025-11-12 08:24:21,450 - INFO - Overall - Precision: 0.5401, Recall: 0.5252, F1: 0.5262\n",
      "2025-11-12 08:24:21,451 - INFO - en - Precision: 0.6263, Recall: 0.5290, F1: 0.5347\n",
      "2025-11-12 08:24:21,451 - INFO - es - Precision: 0.5926, Recall: 0.5286, F1: 0.5242\n",
      "2025-11-12 08:24:21,451 - INFO - it - Precision: 0.4952, Recall: 0.4954, F1: 0.4952\n",
      "2025-11-12 08:24:21,457 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_2_f1_0.5262.pt\n",
      "2025-11-12 08:24:22,101 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_2_f1_0.5262.pt (F1: 0.5262, Fold: 3, Epoch: 2)\n",
      "2025-11-12 08:24:22,101 - INFO - \n",
      "Epoch 4/10\n",
      "2025-11-12 08:24:22,102 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 59.00it/s, loss=0.227]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.19it/s]\n",
      "2025-11-12 08:24:25,171 - INFO - Train Loss: 0.2255\n",
      "2025-11-12 08:24:25,171 - INFO - Val Loss: 0.1404\n",
      "2025-11-12 08:24:25,171 - INFO - Overall - Precision: 0.5558, Recall: 0.5646, F1: 0.5590\n",
      "2025-11-12 08:24:25,172 - INFO - en - Precision: 0.5591, Recall: 0.5224, F1: 0.5251\n",
      "2025-11-12 08:24:25,172 - INFO - es - Precision: 0.5785, Recall: 0.5632, F1: 0.5685\n",
      "2025-11-12 08:24:25,172 - INFO - it - Precision: 0.5236, Recall: 0.5345, F1: 0.5109\n",
      "2025-11-12 08:24:25,178 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_3_f1_0.5590.pt\n",
      "2025-11-12 08:24:25,827 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_3_f1_0.5590.pt (F1: 0.5590, Fold: 3, Epoch: 3)\n",
      "2025-11-12 08:24:25,827 - INFO - \n",
      "Epoch 5/10\n",
      "2025-11-12 08:24:25,828 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.86it/s, loss=0.207]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.29it/s]\n",
      "2025-11-12 08:24:28,903 - INFO - Train Loss: 0.2054\n",
      "2025-11-12 08:24:28,903 - INFO - Val Loss: 0.1508\n",
      "2025-11-12 08:24:28,903 - INFO - Overall - Precision: 0.5908, Recall: 0.6492, F1: 0.5947\n",
      "2025-11-12 08:24:28,903 - INFO - en - Precision: 0.5591, Recall: 0.5224, F1: 0.5251\n",
      "2025-11-12 08:24:28,904 - INFO - es - Precision: 0.5924, Recall: 0.6467, F1: 0.5958\n",
      "2025-11-12 08:24:28,904 - INFO - it - Precision: 0.5831, Recall: 0.6319, F1: 0.5318\n",
      "2025-11-12 08:24:28,910 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_4_f1_0.5947.pt\n",
      "2025-11-12 08:24:29,551 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_4_f1_0.5947.pt (F1: 0.5947, Fold: 3, Epoch: 4)\n",
      "2025-11-12 08:24:29,551 - INFO - \n",
      "Epoch 6/10\n",
      "2025-11-12 08:24:29,552 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.47it/s, loss=0.193]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.46it/s]\n",
      "2025-11-12 08:24:32,650 - INFO - Train Loss: 0.1892\n",
      "2025-11-12 08:24:32,650 - INFO - Val Loss: 0.1412\n",
      "2025-11-12 08:24:32,650 - INFO - Overall - Precision: 0.6188, Recall: 0.6865, F1: 0.6308\n",
      "2025-11-12 08:24:32,651 - INFO - en - Precision: 0.5844, Recall: 0.5257, F1: 0.5297\n",
      "2025-11-12 08:24:32,651 - INFO - es - Precision: 0.5939, Recall: 0.6568, F1: 0.5930\n",
      "2025-11-12 08:24:32,651 - INFO - it - Precision: 0.6366, Recall: 0.7149, F1: 0.6182\n",
      "2025-11-12 08:24:32,657 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_5_f1_0.6308.pt\n",
      "2025-11-12 08:24:33,292 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_5_f1_0.6308.pt (F1: 0.6308, Fold: 3, Epoch: 5)\n",
      "2025-11-12 08:24:33,292 - INFO - \n",
      "Epoch 7/10\n",
      "2025-11-12 08:24:33,293 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 57.98it/s, loss=0.202]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.16it/s]\n",
      "2025-11-12 08:24:36,403 - INFO - Train Loss: 0.1957\n",
      "2025-11-12 08:24:36,404 - INFO - Val Loss: 0.1558\n",
      "2025-11-12 08:24:36,404 - INFO - Overall - Precision: 0.6327, Recall: 0.7312, F1: 0.6405\n",
      "2025-11-12 08:24:36,404 - INFO - en - Precision: 0.6046, Recall: 0.5548, F1: 0.5676\n",
      "2025-11-12 08:24:36,404 - INFO - es - Precision: 0.6255, Recall: 0.7267, F1: 0.6159\n",
      "2025-11-12 08:24:36,404 - INFO - it - Precision: 0.6523, Recall: 0.7416, F1: 0.6067\n",
      "2025-11-12 08:24:36,411 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_6_f1_0.6405.pt\n",
      "2025-11-12 08:24:37,050 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_6_f1_0.6405.pt (F1: 0.6405, Fold: 3, Epoch: 6)\n",
      "2025-11-12 08:24:37,050 - INFO - \n",
      "Epoch 8/10\n",
      "2025-11-12 08:24:37,051 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 59.40it/s, loss=0.171]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 160.67it/s]\n",
      "2025-11-12 08:24:40,115 - INFO - Train Loss: 0.1677\n",
      "2025-11-12 08:24:40,116 - INFO - Val Loss: 0.1369\n",
      "2025-11-12 08:24:40,116 - INFO - Overall - Precision: 0.6785, Recall: 0.7563, F1: 0.7015\n",
      "2025-11-12 08:24:40,116 - INFO - en - Precision: 0.6623, Recall: 0.5614, F1: 0.5810\n",
      "2025-11-12 08:24:40,116 - INFO - es - Precision: 0.6255, Recall: 0.7267, F1: 0.6159\n",
      "2025-11-12 08:24:40,116 - INFO - it - Precision: 0.7446, Recall: 0.8261, F1: 0.7683\n",
      "2025-11-12 08:24:40,122 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_7_f1_0.7015.pt\n",
      "2025-11-12 08:24:40,757 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_7_f1_0.7015.pt (F1: 0.7015, Fold: 3, Epoch: 7)\n",
      "2025-11-12 08:24:40,758 - INFO - \n",
      "Epoch 9/10\n",
      "2025-11-12 08:24:40,759 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 58.81it/s, loss=0.176]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.22it/s]\n",
      "2025-11-12 08:24:43,844 - INFO - Train Loss: 0.1707\n",
      "2025-11-12 08:24:43,844 - INFO - Val Loss: 0.1416\n",
      "2025-11-12 08:24:43,844 - INFO - Overall - Precision: 0.6694, Recall: 0.7548, F1: 0.6914\n",
      "2025-11-12 08:24:43,844 - INFO - en - Precision: 0.5422, Recall: 0.5190, F1: 0.5208\n",
      "2025-11-12 08:24:43,844 - INFO - es - Precision: 0.6194, Recall: 0.7183, F1: 0.6044\n",
      "2025-11-12 08:24:43,845 - INFO - it - Precision: 0.7461, Recall: 0.8447, F1: 0.7694\n",
      "2025-11-12 08:24:43,845 - INFO - \n",
      "Epoch 10/10\n",
      "2025-11-12 08:24:43,846 - INFO - Undersampling: Minority=273, Majority=546\n",
      "Training: 100%|██████████| 137/137 [00:02<00:00, 59.06it/s, loss=0.165]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.68it/s]\n",
      "2025-11-12 08:24:46,919 - INFO - Train Loss: 0.1624\n",
      "2025-11-12 08:24:46,919 - INFO - Val Loss: 0.1295\n",
      "2025-11-12 08:24:46,919 - INFO - Overall - Precision: 0.6825, Recall: 0.7587, F1: 0.7058\n",
      "2025-11-12 08:24:46,919 - INFO - en - Precision: 0.5422, Recall: 0.5190, F1: 0.5208\n",
      "2025-11-12 08:24:46,919 - INFO - es - Precision: 0.6320, Recall: 0.7351, F1: 0.6276\n",
      "2025-11-12 08:24:46,920 - INFO - it - Precision: 0.7640, Recall: 0.8479, F1: 0.7898\n",
      "2025-11-12 08:24:46,926 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_9_f1_0.7058.pt\n",
      "2025-11-12 08:24:47,562 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_3_epoch_9_f1_0.7058.pt (F1: 0.7058, Fold: 3, Epoch: 9)\n",
      "2025-11-12 08:24:47,563 - INFO - \n",
      "================================================================================\n",
      "2025-11-12 08:24:47,563 - INFO - Fold 5/5\n",
      "2025-11-12 08:24:47,563 - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 4:\n",
      "  Train: 272 positive samples\n",
      "  Val:   70 positive samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-11-12 08:24:50,622 - INFO - Froze: Embeddings + First 6 Encoder Layers\n",
      "2025-11-12 08:24:50,622 - INFO - Trainable: Classification Head + Remaining Encoder Layers\n",
      "2025-11-12 08:24:50,622 - INFO - Trainable parameters: 43,119,362 / 278,045,186 (15.51%)\n",
      "2025-11-12 08:24:50,623 - INFO - Label weights: {0: 0.5829268292682926, 1: 3.514705882352941}\n",
      "2025-11-12 08:24:50,623 - INFO - Language weights: {'it': 0.9093912592122662, 'en': 0.961989231586796, 'es': 1.1286195092009375}\n",
      "2025-11-12 08:24:50,624 - INFO - Pos weight (for BCE): 6.0294\n",
      "2025-11-12 08:24:50,625 - INFO - \n",
      "Epoch 1/10\n",
      "2025-11-12 08:24:50,625 - INFO - Undersampling: Minority=272, Majority=544\n",
      "Training: 100%|██████████| 136/136 [00:02<00:00, 58.93it/s, loss=0.352]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 160.10it/s]\n",
      "2025-11-12 08:24:53,703 - INFO - Train Loss: 0.3438\n",
      "2025-11-12 08:24:53,703 - INFO - Val Loss: 0.1180\n",
      "2025-11-12 08:24:53,703 - INFO - Overall - Precision: 0.4269, Recall: 0.5000, F1: 0.4606\n",
      "2025-11-12 08:24:53,703 - INFO - en - Precision: 0.4573, Recall: 0.5000, F1: 0.4777\n",
      "2025-11-12 08:24:53,704 - INFO - es - Precision: 0.4220, Recall: 0.5000, F1: 0.4577\n",
      "2025-11-12 08:24:53,704 - INFO - it - Precision: 0.4023, Recall: 0.5000, F1: 0.4459\n",
      "2025-11-12 08:24:53,712 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_0_f1_0.4606.pt\n",
      "2025-11-12 08:24:54,354 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_0_f1_0.4606.pt (F1: 0.4606, Fold: 4, Epoch: 0)\n",
      "2025-11-12 08:24:54,355 - INFO - \n",
      "Epoch 2/10\n",
      "2025-11-12 08:24:54,356 - INFO - Undersampling: Minority=272, Majority=544\n",
      "Training: 100%|██████████| 136/136 [00:02<00:00, 59.08it/s, loss=0.311]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.13it/s]\n",
      "2025-11-12 08:24:57,405 - INFO - Train Loss: 0.3037\n",
      "2025-11-12 08:24:57,405 - INFO - Val Loss: 0.1135\n",
      "2025-11-12 08:24:57,405 - INFO - Overall - Precision: 0.4266, Recall: 0.4976, F1: 0.4594\n",
      "2025-11-12 08:24:57,405 - INFO - en - Precision: 0.4573, Recall: 0.5000, F1: 0.4777\n",
      "2025-11-12 08:24:57,405 - INFO - es - Precision: 0.4220, Recall: 0.5000, F1: 0.4577\n",
      "2025-11-12 08:24:57,405 - INFO - it - Precision: 0.4012, Recall: 0.4929, F1: 0.4423\n",
      "2025-11-12 08:24:57,405 - INFO - \n",
      "Epoch 3/10\n",
      "2025-11-12 08:24:57,406 - INFO - Undersampling: Minority=272, Majority=544\n",
      "Training: 100%|██████████| 136/136 [00:02<00:00, 58.54it/s, loss=0.259]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 160.24it/s]\n",
      "2025-11-12 08:25:00,490 - INFO - Train Loss: 0.2530\n",
      "2025-11-12 08:25:00,490 - INFO - Val Loss: 0.1281\n",
      "2025-11-12 08:25:00,490 - INFO - Overall - Precision: 0.6378, Recall: 0.5484, F1: 0.5551\n",
      "2025-11-12 08:25:00,491 - INFO - en - Precision: 0.4573, Recall: 0.5000, F1: 0.4777\n",
      "2025-11-12 08:25:00,491 - INFO - es - Precision: 0.7486, Recall: 0.6010, F1: 0.6270\n",
      "2025-11-12 08:25:00,491 - INFO - it - Precision: 0.5491, Recall: 0.5231, F1: 0.5167\n",
      "2025-11-12 08:25:00,497 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_2_f1_0.5551.pt\n",
      "2025-11-12 08:25:01,135 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_2_f1_0.5551.pt (F1: 0.5551, Fold: 4, Epoch: 2)\n",
      "2025-11-12 08:25:01,135 - INFO - \n",
      "Epoch 4/10\n",
      "2025-11-12 08:25:01,136 - INFO - Undersampling: Minority=272, Majority=544\n",
      "Training: 100%|██████████| 136/136 [00:02<00:00, 59.72it/s, loss=0.213]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.74it/s]\n",
      "2025-11-12 08:25:04,167 - INFO - Train Loss: 0.2126\n",
      "2025-11-12 08:25:04,167 - INFO - Val Loss: 0.1664\n",
      "2025-11-12 08:25:04,167 - INFO - Overall - Precision: 0.5287, Recall: 0.5496, F1: 0.5148\n",
      "2025-11-12 08:25:04,167 - INFO - en - Precision: 0.4557, Recall: 0.4800, F1: 0.4675\n",
      "2025-11-12 08:25:04,167 - INFO - es - Precision: 0.5397, Recall: 0.5676, F1: 0.5249\n",
      "2025-11-12 08:25:04,168 - INFO - it - Precision: 0.4889, Recall: 0.4826, F1: 0.4185\n",
      "2025-11-12 08:25:04,168 - INFO - \n",
      "Epoch 5/10\n",
      "2025-11-12 08:25:04,168 - INFO - Undersampling: Minority=272, Majority=544\n",
      "Training: 100%|██████████| 136/136 [00:02<00:00, 58.56it/s, loss=0.215]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 161.71it/s]\n",
      "2025-11-12 08:25:07,244 - INFO - Train Loss: 0.2102\n",
      "2025-11-12 08:25:07,244 - INFO - Val Loss: 0.1680\n",
      "2025-11-12 08:25:07,244 - INFO - Overall - Precision: 0.5579, Recall: 0.6054, F1: 0.5431\n",
      "2025-11-12 08:25:07,244 - INFO - en - Precision: 0.4560, Recall: 0.4833, F1: 0.4693\n",
      "2025-11-12 08:25:07,244 - INFO - es - Precision: 0.5481, Recall: 0.5913, F1: 0.4941\n",
      "2025-11-12 08:25:07,244 - INFO - it - Precision: 0.5536, Recall: 0.5847, F1: 0.4933\n",
      "2025-11-12 08:25:07,245 - INFO - \n",
      "Epoch 6/10\n",
      "2025-11-12 08:25:07,245 - INFO - Undersampling: Minority=272, Majority=544\n",
      "Training: 100%|██████████| 136/136 [00:02<00:00, 58.70it/s, loss=0.218]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.29it/s]\n",
      "2025-11-12 08:25:10,308 - INFO - Train Loss: 0.2146\n",
      "2025-11-12 08:25:10,309 - INFO - Val Loss: 0.1420\n",
      "2025-11-12 08:25:10,309 - INFO - Overall - Precision: 0.6225, Recall: 0.6703, F1: 0.6362\n",
      "2025-11-12 08:25:10,309 - INFO - en - Precision: 0.4568, Recall: 0.4933, F1: 0.4744\n",
      "2025-11-12 08:25:10,309 - INFO - es - Precision: 0.6274, Recall: 0.6660, F1: 0.6399\n",
      "2025-11-12 08:25:10,309 - INFO - it - Precision: 0.6239, Recall: 0.6926, F1: 0.6106\n",
      "2025-11-12 08:25:10,316 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_5_f1_0.6362.pt\n",
      "2025-11-12 08:25:10,959 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_5_f1_0.6362.pt (F1: 0.6362, Fold: 4, Epoch: 5)\n",
      "2025-11-12 08:25:10,960 - INFO - \n",
      "Epoch 7/10\n",
      "2025-11-12 08:25:10,961 - INFO - Undersampling: Minority=272, Majority=544\n",
      "Training: 100%|██████████| 136/136 [00:02<00:00, 58.96it/s, loss=0.183]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 159.43it/s]\n",
      "2025-11-12 08:25:14,032 - INFO - Train Loss: 0.1814\n",
      "2025-11-12 08:25:14,032 - INFO - Val Loss: 0.1770\n",
      "2025-11-12 08:25:14,032 - INFO - Overall - Precision: 0.6094, Recall: 0.6986, F1: 0.6064\n",
      "2025-11-12 08:25:14,032 - INFO - en - Precision: 0.4560, Recall: 0.4833, F1: 0.4693\n",
      "2025-11-12 08:25:14,032 - INFO - es - Precision: 0.5885, Recall: 0.6662, F1: 0.5537\n",
      "2025-11-12 08:25:14,032 - INFO - it - Precision: 0.6501, Recall: 0.7349, F1: 0.5850\n",
      "2025-11-12 08:25:14,032 - INFO - \n",
      "Epoch 8/10\n",
      "2025-11-12 08:25:14,033 - INFO - Undersampling: Minority=272, Majority=544\n",
      "Training: 100%|██████████| 136/136 [00:02<00:00, 59.45it/s, loss=0.163]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.14it/s]\n",
      "2025-11-12 08:25:17,067 - INFO - Train Loss: 0.1632\n",
      "2025-11-12 08:25:17,068 - INFO - Val Loss: 0.1718\n",
      "2025-11-12 08:25:17,068 - INFO - Overall - Precision: 0.6326, Recall: 0.7243, F1: 0.6432\n",
      "2025-11-12 08:25:17,068 - INFO - en - Precision: 0.4557, Recall: 0.4800, F1: 0.4675\n",
      "2025-11-12 08:25:17,068 - INFO - es - Precision: 0.6121, Recall: 0.7116, F1: 0.5761\n",
      "2025-11-12 08:25:17,068 - INFO - it - Precision: 0.6827, Recall: 0.7840, F1: 0.6778\n",
      "2025-11-12 08:25:17,075 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_7_f1_0.6432.pt\n",
      "2025-11-12 08:25:17,715 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_7_f1_0.6432.pt (F1: 0.6432, Fold: 4, Epoch: 7)\n",
      "2025-11-12 08:25:17,715 - INFO - \n",
      "Epoch 9/10\n",
      "2025-11-12 08:25:17,716 - INFO - Undersampling: Minority=272, Majority=544\n",
      "Training: 100%|██████████| 136/136 [00:02<00:00, 58.51it/s, loss=0.171]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 162.11it/s]\n",
      "2025-11-12 08:25:20,792 - INFO - Train Loss: 0.1668\n",
      "2025-11-12 08:25:20,792 - INFO - Val Loss: 0.1854\n",
      "2025-11-12 08:25:20,792 - INFO - Overall - Precision: 0.6338, Recall: 0.7255, F1: 0.6450\n",
      "2025-11-12 08:25:20,793 - INFO - en - Precision: 0.4557, Recall: 0.4800, F1: 0.4675\n",
      "2025-11-12 08:25:20,793 - INFO - es - Precision: 0.5918, Recall: 0.6738, F1: 0.5262\n",
      "2025-11-12 08:25:20,793 - INFO - it - Precision: 0.7162, Recall: 0.8197, F1: 0.7301\n",
      "2025-11-12 08:25:20,799 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_8_f1_0.6450.pt\n",
      "2025-11-12 08:25:21,458 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_8_f1_0.6450.pt (F1: 0.6450, Fold: 4, Epoch: 8)\n",
      "2025-11-12 08:25:21,458 - INFO - \n",
      "Epoch 10/10\n",
      "2025-11-12 08:25:21,459 - INFO - Undersampling: Minority=272, Majority=544\n",
      "Training: 100%|██████████| 136/136 [00:02<00:00, 59.11it/s, loss=0.172]\n",
      "Validating: 100%|██████████| 120/120 [00:00<00:00, 163.60it/s]\n",
      "2025-11-12 08:25:24,504 - INFO - Train Loss: 0.1658\n",
      "2025-11-12 08:25:24,505 - INFO - Val Loss: 0.1642\n",
      "2025-11-12 08:25:24,505 - INFO - Overall - Precision: 0.6403, Recall: 0.7316, F1: 0.6542\n",
      "2025-11-12 08:25:24,505 - INFO - en - Precision: 0.5154, Recall: 0.5271, F1: 0.5122\n",
      "2025-11-12 08:25:24,505 - INFO - es - Precision: 0.5957, Recall: 0.6728, F1: 0.5802\n",
      "2025-11-12 08:25:24,505 - INFO - it - Precision: 0.7461, Recall: 0.8447, F1: 0.7694\n",
      "2025-11-12 08:25:24,512 - INFO - Deleted checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_9_f1_0.6542.pt\n",
      "2025-11-12 08:25:25,146 - INFO - Saved checkpoint: ../fine_tuned_models/checkpoints/fold_4_epoch_9_f1_0.6542.pt (F1: 0.6542, Fold: 4, Epoch: 9)\n",
      "2025-11-12 08:25:25,148 - INFO - \n",
      "Results saved to: ../results/roberta-fine-tune/training_results.csv\n",
      "2025-11-12 08:25:25,149 - INFO - \n",
      "================================================================================\n",
      "2025-11-12 08:25:25,149 - INFO - Best Models Saved:\n",
      "2025-11-12 08:25:25,149 - INFO - ================================================================================\n",
      "2025-11-12 08:25:25,149 - INFO - Fold 2, Epoch 8: F1=0.7352 -> ../fine_tuned_models/checkpoints/fold_2_epoch_8_f1_0.7352.pt\n",
      "2025-11-12 08:25:25,149 - INFO - Fold 2, Epoch 7: F1=0.7281 -> ../fine_tuned_models/checkpoints/fold_2_epoch_7_f1_0.7281.pt\n"
     ]
    }
   ],
   "source": [
    "main(train_df, Config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441cdbe3-5836-4a17-901e-ed0a869d03d3",
   "metadata": {},
   "source": [
    "# Visualizing Fine-Tune Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29fc7190-5d13-4a71-8ca8-58f1b300296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../results/roberta-fine-tune/training_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90bb34b6-16a0-4c2f-90f6-18480f987d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../figures/f1_vs_fold.svg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_plot = alt.Chart(df).mark_line(point=True, size=3).encode(\n",
    "    x=alt.X('epoch:Q', title='Epoch'),\n",
    "    y=alt.Y('overall_macro_f1:Q', title='Macro F1 Score', scale=alt.Scale(domain=[0.3, 0.8])),\n",
    "    color=alt.Color('fold:N', title='Fold'),\n",
    "    tooltip=['fold:N', 'epoch:Q', alt.Tooltip('overall_macro_f1:Q', format='.4f')]\n",
    ").properties(width=600, height=300, title='Overall F1 Score by Fold')\n",
    "f1_plot.save(os.path.join(figures_root, 'f1_vs_fold.svg'))\n",
    "os.path.join(figures_root, 'f1_vs_fold.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10504305-3064-4173-9be7-88629e0cd66f",
   "metadata": {},
   "source": [
    "![](../figures/f1_vs_fold.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46e229da-2e44-4497-abb2-085059f53f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../figures/loss.svg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_data = df[['fold', 'epoch', 'train_loss', 'val_loss']].melt(\n",
    "    id_vars=['fold', 'epoch'], var_name='loss_type', value_name='loss'\n",
    ")\n",
    "\n",
    "loss_plot = alt.Chart(loss_data).mark_line(point=True).encode(\n",
    "    x='epoch:Q', y='loss:Q', color='loss_type:N', strokeDash='fold:N',\n",
    "    tooltip=['fold:N', 'epoch:Q', 'loss_type:N', alt.Tooltip('loss:Q', format='.4f')]\n",
    ").properties(width=600, height=300, title='Training & Validation Loss')\n",
    "\n",
    "loss_plot.save(os.path.join(figures_root, 'loss.svg'))\n",
    "os.path.join(figures_root, 'loss.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26ad030-7d3e-48ee-8728-d5f5bd0059de",
   "metadata": {},
   "source": [
    "![](../figures/loss.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f2d4cc-f8fe-4499-99bb-a60bbdf49d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../figures/f1_vs_lang.svg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_data = df[['fold', 'epoch', 'en_macro_f1', 'es_macro_f1', 'it_macro_f1']].melt(\n",
    "    id_vars=['fold', 'epoch'], var_name='language', value_name='f1'\n",
    ")\n",
    "lang_data['language'] = lang_data['language'].str.replace('_macro_f1', '').str.upper()\n",
    "\n",
    "lang_plot = alt.Chart(lang_data).mark_line(point=True).encode(\n",
    "    x='epoch:Q', y=alt.Y('f1:Q', scale=alt.Scale(domain=[0.4, 0.95])), color='language:N', strokeDash='fold:N',\n",
    "    tooltip=['fold:N', 'epoch:Q', 'language:N', alt.Tooltip('f1:Q', format='.4f')]\n",
    ").properties(width=600, height=300, title='F1 by Language')\n",
    "\n",
    "lang_plot.save(os.path.join(figures_root, 'f1_vs_lang.svg'))\n",
    "os.path.join(figures_root, 'f1_vs_lang.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a33e3da-f2d1-41b0-a7a6-d3379bdc93af",
   "metadata": {},
   "source": [
    "![](../figures/f1_vs_lang.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d63ee4b-3eb6-4e82-bd83-4b33ac27ad39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../figures/fold_vs_epoch.svg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_data = df[['fold', 'epoch', 'overall_macro_precision', 'overall_macro_recall', 'overall_macro_f1']].melt(\n",
    "    id_vars=['fold', 'epoch'], var_name='metric', value_name='value'\n",
    ")\n",
    "metrics_data['metric'] = metrics_data['metric'].str.replace('overall_macro_', '').str.capitalize()\n",
    "metrics_data['fold_epoch'] = 'F' + metrics_data['fold'].astype(str) + ':E' + metrics_data['epoch'].astype(str)\n",
    "\n",
    "heatmap = alt.Chart(metrics_data).mark_rect().encode(\n",
    "    x='fold_epoch:O', y='metric:N',\n",
    "    color=alt.Color('value:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    tooltip=['fold_epoch:N', 'metric:N', alt.Tooltip('value:Q', format='.4f')]\n",
    ").properties(width=700, height=150, title='Precision/Recall/F1 Heatmap')\n",
    "\n",
    "heatmap.save(os.path.join(figures_root, 'fold_vs_epoch.svg'))\n",
    "os.path.join(figures_root, 'fold_vs_epoch.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20e51b-b899-45f7-9505-3fab9ed2b9ff",
   "metadata": {},
   "source": [
    "![](../figures/fold_vs_epoch.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70767ef2-72c2-44f6-8150-b6b342f6b68f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipride",
   "language": "python",
   "name": "multipride"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
