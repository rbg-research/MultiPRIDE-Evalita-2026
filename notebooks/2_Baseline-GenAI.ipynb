{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8dbf7e2-d414-4b21-9d4a-b0bc1736b5d6",
   "metadata": {},
   "source": [
    "# Hosting vLLM on server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff50def-baaa-40d4-b845-b38b780305a0",
   "metadata": {},
   "source": [
    "```\n",
    "python -m vllm.entrypoints.openai.api_server --model HuggingFaceTB/SmolLM3-3B --dtype bfloat16 --gpu-memory-utilization 0.85 --max-model-len 2048 --port 9999 --tensor-parallel-size 1 --enable-prefix-caching --trust-remote-code\n",
    "\n",
    "```\n",
    "\n",
    "* HuggingFaceTB/SmolLM3-3B\n",
    "* microsoft/Phi-3.5-mini-instruct\n",
    "* tiiuae/Falcon3-3B-Instruct\n",
    "* Qwen/Qwen2.5-Omni-7B\n",
    "* google/gemma-3n-E4B-it\n",
    "* meta-llama/Llama-3.2-3B-Instruct\n",
    "* meta-llama/Llama-3.1-8B-Instruct\n",
    "* Qwen/Qwen2.5-7B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897c76df-3e1f-4038-9129-761d2fe8c1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All random seeds set to 42\n",
      "✓ All random seeds set to 42\n",
      "training files: ['train_en.csv', 'train_es.csv', 'train_it.csv']\n",
      "Total training samples: 2988\n",
      "================================================================================\n",
      "CLASS DISTRIBUTION\n",
      "================================================================================\n",
      "\n",
      "Overall:\n",
      "  Class 0 (NOT_RECLAMATORY): 2560 (85.7%)\n",
      "  Class 1 (RECLAMATORY): 428 (14.3%)\n",
      "  Total: 2988\n",
      "\n",
      "Per Language:\n",
      "  EN: Class 0=938, Class 1=88, Total=1026\n",
      "  ES: Class 0=743, Class 1=133, Total=876\n",
      "  IT: Class 0=879, Class 1=207, Total=1086\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from src.config import *\n",
    "from src.genai import GenAIClassifier\n",
    "from src.baseline import train_df\n",
    "from src.utils import (calculate_language_wise_metrics, calculate_metrics, calculate_overall_metrics, \\\n",
    "create_comparison_table, print_results, generate_detailed_report, get_random_examples, get_misclassified_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be0f16-6286-40ef-b306-13b940dbee8c",
   "metadata": {},
   "source": [
    "# Zero-Shot-Learning: Chain-of-Thoughts Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244abfe2-e5ca-4a58-8884-61b215849aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"HuggingFaceTB/SmolLM3-3B\"\n",
    "# model_name = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "# model_name = \"tiiuae/Falcon3-3B-Instruct\"\n",
    "# model_name = \"Qwen/Qwen2.5-Omni-7B\"\n",
    "# model_name = \"google/gemma-3n-E4B-it\"\n",
    "# model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "# model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "# OOM Models\n",
    "# model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "genai_classifier = GenAIClassifier(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4969b95-6b1f-4876-9642-6209850c6df8",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a8c0d8-bf7e-438f-bdf0-32f913ea9db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            You are a linguistic expert specializing in LGBTQ+ discourse analysis.\n",
      "            \n",
      "            TASK: Classify whether LGBTQ+ terminology uses RECLAMATORY INTENT\n",
      "            \n",
      "            Strictly give final classification answer only, don't give any explanation.\n",
      "            \n",
      "            DEFINITIONS:\n",
      "            - RECLAMATORY: Term used for identity affirmation, pride, empowerment, community solidarity\n",
      "            - NOT_RECLAMATORY: Derogatory use, neutral mention, or unclear intent\n",
      "            \n",
      "            Tweet (Language: English): \"I've never heard anyone use the word \"faggot\" and not sound like an insecure 13 year old. \"\n",
      "            \n",
      "            ANALYSIS (Chain of Thought):\n",
      "            \n",
      "            1. TERM IDENTIFICATION: What LGBTQ+ terms appear?\n",
      "            2. TONE & MARKERS: What emotional/linguistic indicators are present?\n",
      "            3. CONTEXT: Is it community affirmation or external discourse?\n",
      "            4. INTENT: Does it express reclamatory intent?\n",
      "            \n",
      "            Classification: [RECLAMATORY / NOT_RECLAMATORY]\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(genai_classifier.create_prompt_zero_shot(train_df.text[0], train_df.lang[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b433083e-83a6-4b91-aa3e-9d1b006bb433",
   "metadata": {},
   "source": [
    "### Sample Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d789e37d-60a2-49da-92a4-3e6e7354d8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet': 'I\\'ve never heard anyone use the word \"faggot\" and not sound like an insecure 13 year old. ',\n",
       " 'language': 'en',\n",
       " 'classification': 'NOT_RECLAMATORY',\n",
       " 'classification_label': 0,\n",
       " 'raw_response': '<think>\\n\\n</think>\\nNOT_RECLAMATORY',\n",
       " 'model': 'HuggingFaceTB/SmolLM3-3B',\n",
       " 'prompt_type': 'zero-shot'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = genai_classifier.classify(train_df.text[0], train_df.lang[0], use_few_shot=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa206c-2ccd-40fc-843f-1f5d1bacde20",
   "metadata": {},
   "source": [
    "### Running for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8433b-c3fb-404f-a2b1-c896813ba20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for row in tqdm(train_df.itertuples(index=False), total=len(train_df), desc=\"Classifying\"):\n",
    "    result = genai_classifier.classify(row.text, row.lang, use_few_shot=False)\n",
    "    predicted_labels.append(result[\"classification_label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5ecb84-f353-4d9d-81b9-05f6af86ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"train_cot_prompt.csv\"\n",
    "results_write_path = os.path.join(results_root, result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a908990e-85c6-443f-8fd2-b3b1e037f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(results_write_path):\n",
    "    result_df = pd.read_csv(results_write_path)\n",
    "else:\n",
    "    result_df = train_df[[\"id\", \"lang\", \"label\"]]\n",
    "\n",
    "result_df[model_name] = predicted_labels\n",
    "\n",
    "result_df.to_csv(results_write_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1a0f2-6732-4bd7-91d1-d704d87c3b6f",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7346ca97-b712-489a-8017-d753bd00b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv(results_write_path)\n",
    "model_columns = [m for m in list(result_df.columns) if m not in [\"id\", \"lang\", \"label\"]]\n",
    "model_names = {}\n",
    "for model_column in model_columns:\n",
    "    model_names[model_column] = model_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f406a48f-1e1f-4405-8bd5-44cb5d5615e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OVERALL METRICS (All Languages)\n",
      "================================================================================\n",
      " accuracy  precision   recall       f1                            model  n_samples\n",
      " 0.589829   0.548119 0.589829 0.528832         HuggingFaceTB/SmolLM3-3B       2988\n",
      " 0.608895   0.553459 0.608895 0.490063  microsoft/Phi-3.5-mini-instruct       2988\n",
      " 0.554587   0.551341 0.554587 0.280033       tiiuae/Falcon3-3B-Instruct       2988\n",
      " 0.539800   0.519664 0.539800 0.463701             Qwen/Qwen2.5-Omni-7B       2988\n",
      " 0.537883   0.518870 0.537883 0.469295           google/gemma-3n-E4B-it       2988\n",
      " 0.571904   0.538389 0.571904 0.516257 meta-llama/Llama-3.1-8B-Instruct       2988\n",
      " 0.600805   0.550280 0.600805 0.507662         Qwen/Qwen2.5-7B-Instruct       2988\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LANGUAGE-WISE METRICS\n",
      "================================================================================\n",
      "\n",
      "EN Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                           model  accuracy  precision   recall       f1  n_samples\n",
      "        HuggingFaceTB/SmolLM3-3B  0.672890   0.594967 0.672890 0.612180       1026\n",
      " microsoft/Phi-3.5-mini-instruct  0.692419   0.601235 0.692419 0.619981       1026\n",
      "      tiiuae/Falcon3-3B-Instruct  0.581472   0.526403 0.581472 0.386657       1026\n",
      "            Qwen/Qwen2.5-Omni-7B  0.626175   0.559128 0.626175 0.562159       1026\n",
      "          google/gemma-3n-E4B-it  0.633444   0.556625 0.633444 0.552997       1026\n",
      "meta-llama/Llama-3.1-8B-Instruct  0.600819   0.580044 0.600819 0.588172       1026\n",
      "        Qwen/Qwen2.5-7B-Instruct  0.687076   0.583829 0.687076 0.592740       1026\n",
      "\n",
      "ES Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                           model  accuracy  precision   recall       f1  n_samples\n",
      "        HuggingFaceTB/SmolLM3-3B  0.622588   0.565213 0.622588 0.465232        876\n",
      " microsoft/Phi-3.5-mini-instruct  0.590777   0.571310 0.590777 0.340486        876\n",
      "      tiiuae/Falcon3-3B-Instruct  0.503643   0.534722 0.503643 0.146967        876\n",
      "            Qwen/Qwen2.5-Omni-7B  0.564740   0.548176 0.564740 0.336861        876\n",
      "          google/gemma-3n-E4B-it  0.557636   0.532805 0.557636 0.399769        876\n",
      "meta-llama/Llama-3.1-8B-Instruct  0.619132   0.569396 0.619132 0.424677        876\n",
      "        Qwen/Qwen2.5-7B-Instruct  0.614097   0.573487 0.614097 0.393579        876\n",
      "\n",
      "IT Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                           model  accuracy  precision   recall       f1  n_samples\n",
      "        HuggingFaceTB/SmolLM3-3B  0.496018   0.497262 0.496018 0.482574       1086\n",
      " microsoft/Phi-3.5-mini-instruct  0.514402   0.508983 0.514402 0.439736       1086\n",
      "      tiiuae/Falcon3-3B-Instruct  0.509959   0.561167 0.509959 0.190721       1086\n",
      "            Qwen/Qwen2.5-Omni-7B  0.435722   0.459702 0.435722 0.418623       1086\n",
      "          google/gemma-3n-E4B-it  0.439127   0.462074 0.439127 0.417955       1086\n",
      "meta-llama/Llama-3.1-8B-Instruct  0.481097   0.487000 0.481097 0.470760       1086\n",
      "        Qwen/Qwen2.5-7B-Instruct  0.515317   0.509805 0.515317 0.483787       1086\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MODEL RANKING (by F1-Score)\n",
      "================================================================================\n",
      " rank                            model       f1  accuracy  precision   recall  n_samples\n",
      "    1         HuggingFaceTB/SmolLM3-3B 0.528832  0.589829   0.548119 0.589829       2988\n",
      "    2 meta-llama/Llama-3.1-8B-Instruct 0.516257  0.571904   0.538389 0.571904       2988\n",
      "    3         Qwen/Qwen2.5-7B-Instruct 0.507662  0.600805   0.550280 0.600805       2988\n",
      "    4  microsoft/Phi-3.5-mini-instruct 0.490063  0.608895   0.553459 0.608895       2988\n",
      "    5           google/gemma-3n-E4B-it 0.469295  0.537883   0.518870 0.537883       2988\n",
      "    6             Qwen/Qwen2.5-Omni-7B 0.463701  0.539800   0.519664 0.539800       2988\n",
      "    7       tiiuae/Falcon3-3B-Instruct 0.280033  0.554587   0.551341 0.554587       2988\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DETAILED REPORT: HuggingFaceTB/SmolLM3-3B\n",
      "================================================================================\n",
      "\n",
      "Overall Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.89      0.67      0.77      2560\n",
      "    RECLAMATORY       0.21      0.51      0.29       428\n",
      "\n",
      "       accuracy                           0.65      2988\n",
      "      macro avg       0.55      0.59      0.53      2988\n",
      "   weighted avg       0.79      0.65      0.70      2988\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted NOT    Predicted REC\n",
      "Actual NOT      1716             844            \n",
      "Actual REC      210              218            \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Per-Language Reports:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "EN Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.95      0.86      0.90       938\n",
      "    RECLAMATORY       0.24      0.49      0.32        88\n",
      "\n",
      "       accuracy                           0.83      1026\n",
      "      macro avg       0.59      0.67      0.61      1026\n",
      "   weighted avg       0.89      0.83      0.85      1026\n",
      "\n",
      "\n",
      "ES Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.93      0.45      0.60       743\n",
      "    RECLAMATORY       0.21      0.80      0.33       133\n",
      "\n",
      "       accuracy                           0.50       876\n",
      "      macro avg       0.57      0.62      0.47       876\n",
      "   weighted avg       0.82      0.50      0.56       876\n",
      "\n",
      "\n",
      "IT Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.81      0.66      0.73       879\n",
      "    RECLAMATORY       0.19      0.33      0.24       207\n",
      "\n",
      "       accuracy                           0.60      1086\n",
      "      macro avg       0.50      0.50      0.48      1086\n",
      "   weighted avg       0.69      0.60      0.63      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = result_df\n",
    "    \n",
    "overall_metrics = calculate_overall_metrics(df, model_columns, model_names)\n",
    "\n",
    "language_metrics = calculate_language_wise_metrics(df, model_columns, model_names)\n",
    "\n",
    "print_results(overall_metrics, language_metrics)\n",
    "\n",
    "ranking = create_comparison_table(overall_metrics)\n",
    "\n",
    "best_model = ranking.iloc[0]['model']\n",
    "best_model_col = [k for k, v in model_names.items() if v == best_model][0]\n",
    "generate_detailed_report(df, best_model_col, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b4286-efed-4b73-8c4d-b12bbc143105",
   "metadata": {},
   "source": [
    "# Few-Shot-Learning: Chain-of-Thoughts Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d125d81-b1cb-478d-9386-4550f31e6370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HuggingFaceTB/SmolLM3-3B'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_samples_model_name = best_model\n",
    "negative_samples_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8da3c06-fe68-4d51-8ac1-c83df277e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_df = pd.read_csv(results_write_path)\n",
    "cot_df = cot_df[[\"id\", model_name]]\n",
    "merged_df = pd.merge(train_df, cot_df, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b62d0b-6031-4b93-a4d9-d761b3f23358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN: 2 class 0 + 2 class 1 = 4 total\n",
      "ES: 2 class 0 + 2 class 1 = 4 total\n",
      "IT: 2 class 0 + 2 class 1 = 4 total\n",
      "EN: 2 misclassified class 0 + 2 misclassified class 1 = 4 total\n",
      "ES: 2 misclassified class 0 + 2 misclassified class 1 = 4 total\n",
      "IT: 2 misclassified class 0 + 2 misclassified class 1 = 4 total\n"
     ]
    }
   ],
   "source": [
    "N_EXAMPLES_PER_CLASS = 2\n",
    "PREDICTION_COLUMN = negative_samples_model_name\n",
    "\n",
    "random_examples = get_random_examples(\n",
    "        df=merged_df,\n",
    "        n_examples_per_class=N_EXAMPLES_PER_CLASS\n",
    "    )\n",
    "\n",
    "misclassified_examples = get_misclassified_examples(\n",
    "        df=merged_df,\n",
    "        prediction_col=PREDICTION_COLUMN,\n",
    "        n_examples_per_class=N_EXAMPLES_PER_CLASS\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c224b52-a1d4-4d57-9065-1f4534d6936a",
   "metadata": {},
   "source": [
    "### CoT + Random Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab735477-1fa5-4203-b377-95c57204bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_random = GenAIClassifier(model_name=model_name, examples_dict=random_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d9d25e-08c7-42a7-8888-5b0bc12a732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            You are a linguistic expert specializing in LGBTQ+ discourse analysis.\n",
      "            \n",
      "            TASK: Classify whether LGBTQ+ terminology uses RECLAMATORY INTENT\n",
      "            \n",
      "            Strictly give final classification answer only, don't give any explanation.\n",
      "            \n",
      "            DEFINITIONS:\n",
      "            - RECLAMATORY: Term used for identity affirmation, pride, empowerment, community solidarity\n",
      "            - NOT_RECLAMATORY: Derogatory use, neutral mention, or unclear intent\n",
      "            \n",
      "            EXAMPLES:\n",
      "            The following are some examples of LGBTQ+ tweets in English:\n",
      "            \n",
      "            Tweet: \"Maybe you're really just joking, but I don't get why other people on this site like to mock those who identify as other genders. The \"I identify as a car\" jokes are as blatant and tired as nigger jokes. And for the most part, it's not your caricature coal miner from the rust belt. It's so-called liberal progressives who believe in things like gay rights/marriage equality. \n",
      "\n",
      "\n",
      "**Edit:** To all the \"HOW DARE YOU COMPARE THIS TO THE PLIGHT OF BLACK PEOPLE IN AMERICA\" types \n",
      "\n",
      "[Ayyyy lmao](URL\" Label: NOT_RECLAMATORY\n",
      "---\n",
      "Tweet: \"And to be fair, getting triggered by slurs is just stupid to begin with. Yeah I'm a faggot, yeah I'm gay. I'm more offended by being called homosexual because it has more syllables and thus takes more time to say.\" Label: RECLAMATORY\n",
      "---\n",
      "Tweet: \"Thanks for the support, the problem is my friends hardly like me. They more just tolerant me but at least they will support me for now. I get tired of hearing the faggot all around me it get's tiring some times I just want to sleep.   \" Label: NOT_RECLAMATORY\n",
      "---\n",
      "Tweet: \"Somewhat same here. I was one my bus and kids kept calling me a faggot bc they found out that I have a girlfriend and acted like I have a disease. Turns out I have the big gay disease that can spread to anyone who gazes apon my beautiful face uwu\" Label: RECLAMATORY\n",
      "            \n",
      "            Based on the observations from the DEFINITIONS and the EXAMPLES, classify the following tweet in English:\n",
      "            \n",
      "            Tweet : \"I've never heard anyone use the word \"faggot\" and not sound like an insecure 13 year old. \"\n",
      "            \n",
      "            Classification: [RECLAMATORY / NOT_RECLAMATORY]\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(classifier_random.create_prompt_few_shot(train_df.text[0], train_df.lang[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d35f3fce-c5da-442f-8a60-175bef657b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet': 'I\\'ve never heard anyone use the word \"faggot\" and not sound like an insecure 13 year old. ',\n",
       " 'language': 'en',\n",
       " 'classification': 'RECLAMATORY',\n",
       " 'classification_label': 1,\n",
       " 'raw_response': '<think>\\n\\n</think>\\nClassification: RECLAMATORY',\n",
       " 'model': 'HuggingFaceTB/SmolLM3-3B',\n",
       " 'prompt_type': 'few-shot'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classifier_random.classify(\n",
    "        q_tweet=train_df.text[0],\n",
    "        q_language=train_df.lang[0],\n",
    "        use_few_shot=True\n",
    "    )\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220bbfa-2139-4876-b632-59c750ec38c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for row in tqdm(train_df.itertuples(index=False), total=len(train_df), desc=\"Classifying\"):\n",
    "    result = classifier_random.classify(row.text, row.lang, use_few_shot=True)\n",
    "    predicted_labels.append(result[\"classification_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "192fd66c-7f8a-44f5-b503-7a49b1e21d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_write_path = os.path.join(results_root, f\"train_fewshot_prompt_random_{N_EXAMPLES_PER_CLASS}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ba93f-d21b-41b0-a620-ea730ac8c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(results_write_path):\n",
    "    result_df = pd.read_csv(results_write_path)\n",
    "else:\n",
    "    result_df = train_df[[\"id\", \"lang\", \"label\"]]\n",
    "\n",
    "result_df[model_name] = predicted_labels\n",
    "\n",
    "result_df.to_csv(results_write_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96be09bc-dd67-4a50-b960-f62980635710",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df = pd.read_csv(f\"../results/train/train_fewshot_prompt_random_{N_EXAMPLES_PER_CLASS}.csv\")\n",
    "random_df = random_df.fillna(0)\n",
    "\n",
    "model_columns = [m for m in list(random_df.columns) if m not in [\"id\", \"lang\", \"label\"]]\n",
    "model_names = {}\n",
    "for model_column in model_columns:\n",
    "    model_names[model_column] = model_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "903546f7-1ee2-4180-8ed4-2ce092a65033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OVERALL METRICS (All Languages)\n",
      "================================================================================\n",
      " accuracy  precision   recall       f1                            model  n_samples\n",
      " 0.571326   0.536609 0.571326 0.423819 meta-llama/Llama-3.1-8B-Instruct       2988\n",
      " 0.598009   0.548177 0.598009 0.489374         Qwen/Qwen2.5-7B-Instruct       2988\n",
      " 0.544166   0.564862 0.544166 0.228566         HuggingFaceTB/SmolLM3-3B       2988\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LANGUAGE-WISE METRICS\n",
      "================================================================================\n",
      "\n",
      "EN Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                           model  accuracy  precision   recall       f1  n_samples\n",
      "meta-llama/Llama-3.1-8B-Instruct  0.656244   0.549387 0.656244 0.435194       1026\n",
      "        Qwen/Qwen2.5-7B-Instruct  0.728072   0.587301 0.728072 0.584289       1026\n",
      "        HuggingFaceTB/SmolLM3-3B  0.621366   0.551500 0.621366 0.309072       1026\n",
      "\n",
      "ES Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                           model  accuracy  precision   recall       f1  n_samples\n",
      "meta-llama/Llama-3.1-8B-Instruct  0.616860   0.585414 0.616860 0.367303        876\n",
      "        Qwen/Qwen2.5-7B-Instruct  0.641805   0.585644 0.641805 0.425445        876\n",
      "        HuggingFaceTB/SmolLM3-3B  0.511440   0.577416 0.511440 0.156441        876\n",
      "\n",
      "IT Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                           model  accuracy  precision   recall       f1  n_samples\n",
      "meta-llama/Llama-3.1-8B-Instruct  0.499918   0.499949 0.499918 0.438559       1086\n",
      "        Qwen/Qwen2.5-7B-Instruct  0.468525   0.480575 0.468525 0.426924       1086\n",
      "        HuggingFaceTB/SmolLM3-3B  0.489060   0.236462 0.489060 0.159334       1086\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MODEL RANKING (by F1-Score)\n",
      "================================================================================\n",
      " rank                            model       f1  accuracy  precision   recall  n_samples\n",
      "    1         Qwen/Qwen2.5-7B-Instruct 0.489374  0.598009   0.548177 0.598009       2988\n",
      "    2 meta-llama/Llama-3.1-8B-Instruct 0.423819  0.571326   0.536609 0.571326       2988\n",
      "    3         HuggingFaceTB/SmolLM3-3B 0.228566  0.544166   0.564862 0.544166       2988\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DETAILED REPORT: Qwen/Qwen2.5-7B-Instruct\n",
      "================================================================================\n",
      "\n",
      "Overall Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.90      0.55      0.68      2560\n",
      "    RECLAMATORY       0.19      0.65      0.30       428\n",
      "\n",
      "       accuracy                           0.56      2988\n",
      "      macro avg       0.55      0.60      0.49      2988\n",
      "   weighted avg       0.80      0.56      0.63      2988\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted NOT    Predicted REC\n",
      "Actual NOT      1399             1161           \n",
      "Actual REC      150              278            \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Per-Language Reports:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "EN Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.96      0.75      0.84       938\n",
      "    RECLAMATORY       0.21      0.70      0.32        88\n",
      "\n",
      "       accuracy                           0.75      1026\n",
      "      macro avg       0.59      0.73      0.58      1026\n",
      "   weighted avg       0.90      0.75      0.80      1026\n",
      "\n",
      "\n",
      "ES Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.97      0.35      0.52       743\n",
      "    RECLAMATORY       0.20      0.93      0.34       133\n",
      "\n",
      "       accuracy                           0.44       876\n",
      "      macro avg       0.59      0.64      0.43       876\n",
      "   weighted avg       0.85      0.44      0.49       876\n",
      "\n",
      "\n",
      "IT Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.79      0.49      0.61       879\n",
      "    RECLAMATORY       0.17      0.44      0.25       207\n",
      "\n",
      "       accuracy                           0.48      1086\n",
      "      macro avg       0.48      0.47      0.43      1086\n",
      "   weighted avg       0.67      0.48      0.54      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = random_df\n",
    "    \n",
    "overall_metrics = calculate_overall_metrics(df, model_columns, model_names)\n",
    "\n",
    "language_metrics = calculate_language_wise_metrics(df, model_columns, model_names)\n",
    "\n",
    "print_results(overall_metrics, language_metrics)\n",
    "\n",
    "ranking = create_comparison_table(overall_metrics)\n",
    "\n",
    "best_model = ranking.iloc[0]['model']\n",
    "best_model_col = [k for k, v in model_names.items() if v == best_model][0]\n",
    "generate_detailed_report(df, best_model_col, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f3cfdc-41fe-4f30-b1d5-faccb68e35e1",
   "metadata": {},
   "source": [
    "### Misclassifed Zero Shot Examples + CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73dab8e7-f856-4b4d-b5ab-5eff2cc42d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_misclass = GenAIClassifier(model_name=model_name, examples_dict=misclassified_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8599101-43a2-45e2-bbb8-13f156eecbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet': 'I\\'ve never heard anyone use the word \"faggot\" and not sound like an insecure 13 year old. ',\n",
       " 'language': 'en',\n",
       " 'classification': 'RECLAMATORY',\n",
       " 'classification_label': 1,\n",
       " 'raw_response': '<think>\\n\\n</think>\\nClassification: RECLAMATORY',\n",
       " 'model': 'HuggingFaceTB/SmolLM3-3B',\n",
       " 'prompt_type': 'few-shot'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classifier_misclass.classify(\n",
    "        q_tweet=train_df.text[0],\n",
    "        q_language=train_df.lang[0],\n",
    "        use_few_shot=True\n",
    "    )\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e7812-3e57-444c-8350-4e61911f5ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for row in tqdm(train_df.itertuples(index=False), total=len(train_df), desc=\"Classifying\"):\n",
    "    result = classifier_misclass.classify(row.text, row.lang, use_few_shot=True)\n",
    "    predicted_labels.append(result[\"classification_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24874f57-159a-4262-80f5-773df128db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_write_path = os.path.join(results_root, f\"train_fewshot_prompt_misclassy_{N_EXAMPLES_PER_CLASS}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d0487-f168-47cc-8a9c-50b6ec896f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(results_write_path):\n",
    "    result_df = pd.read_csv(results_write_path)\n",
    "else:\n",
    "    result_df = train_df[[\"id\", \"lang\", \"label\"]]\n",
    "\n",
    "result_df[model_name] = predicted_labels\n",
    "\n",
    "result_df.to_csv(results_write_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9884a46c-e5a2-485a-ae0c-d44d057fa9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclass_df = pd.read_csv(f\"../results/train/train_fewshot_prompt_misclassy_{N_EXAMPLES_PER_CLASS}.csv\")\n",
    "misclass_df = misclass_df.fillna(0)\n",
    "\n",
    "model_columns = [m for m in list(misclass_df.columns) if m not in [\"id\", \"lang\", \"label\"]]\n",
    "model_names = {}\n",
    "for model_column in model_columns:\n",
    "    model_names[model_column] = model_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "101dad54-415c-48d3-b575-435d37ed4099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OVERALL METRICS (All Languages)\n",
      "================================================================================\n",
      " accuracy  precision   recall       f1                            model  n_samples\n",
      " 0.551639   0.526700 0.551639 0.409892 meta-llama/Llama-3.1-8B-Instruct       2988\n",
      " 0.622795   0.560868 0.622795 0.515542         Qwen/Qwen2.5-7B-Instruct       2988\n",
      " 0.523091   0.544956 0.523091 0.198224         HuggingFaceTB/SmolLM3-3B       2988\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LANGUAGE-WISE METRICS\n",
      "================================================================================\n",
      "\n",
      "EN Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                           model  accuracy  precision   recall       f1  n_samples\n",
      "meta-llama/Llama-3.1-8B-Instruct  0.654124   0.548378 0.654124 0.448546       1026\n",
      "        Qwen/Qwen2.5-7B-Instruct  0.745675   0.611808 0.745675 0.630595       1026\n",
      "        HuggingFaceTB/SmolLM3-3B  0.560780   0.538394 0.560780 0.222398       1026\n",
      "\n",
      "ES Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                           model  accuracy  precision   recall       f1  n_samples\n",
      "meta-llama/Llama-3.1-8B-Instruct  0.616187   0.585223 0.616187 0.366266        876\n",
      "        Qwen/Qwen2.5-7B-Instruct  0.673155   0.597521 0.673155 0.465627        876\n",
      "        HuggingFaceTB/SmolLM3-3B  0.525572   0.579356 0.525572 0.185628        876\n",
      "\n",
      "IT Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                           model  accuracy  precision   recall       f1  n_samples\n",
      "meta-llama/Llama-3.1-8B-Instruct  0.445327   0.465454 0.445327 0.385625       1086\n",
      "        Qwen/Qwen2.5-7B-Instruct  0.480314   0.487846 0.480314 0.430588       1086\n",
      "        HuggingFaceTB/SmolLM3-3B  0.481674   0.292437 0.481674 0.161641       1086\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MODEL RANKING (by F1-Score)\n",
      "================================================================================\n",
      " rank                            model       f1  accuracy  precision   recall  n_samples\n",
      "    1         Qwen/Qwen2.5-7B-Instruct 0.515542  0.622795   0.560868 0.622795       2988\n",
      "    2 meta-llama/Llama-3.1-8B-Instruct 0.409892  0.551639   0.526700 0.551639       2988\n",
      "    3         HuggingFaceTB/SmolLM3-3B 0.198224  0.523091   0.544956 0.523091       2988\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DETAILED REPORT: Qwen/Qwen2.5-7B-Instruct\n",
      "================================================================================\n",
      "\n",
      "Overall Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.91      0.58      0.71      2560\n",
      "    RECLAMATORY       0.21      0.66      0.32       428\n",
      "\n",
      "       accuracy                           0.60      2988\n",
      "      macro avg       0.56      0.62      0.52      2988\n",
      "   weighted avg       0.81      0.60      0.66      2988\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted NOT    Predicted REC\n",
      "Actual NOT      1496             1064           \n",
      "Actual REC      145              283            \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Per-Language Reports:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "EN Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.96      0.82      0.89       938\n",
      "    RECLAMATORY       0.26      0.67      0.37        88\n",
      "\n",
      "       accuracy                           0.81      1026\n",
      "      macro avg       0.61      0.75      0.63      1026\n",
      "   weighted avg       0.90      0.81      0.84      1026\n",
      "\n",
      "\n",
      "ES Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.97      0.41      0.57       743\n",
      "    RECLAMATORY       0.22      0.94      0.36       133\n",
      "\n",
      "       accuracy                           0.49       876\n",
      "      macro avg       0.60      0.67      0.47       876\n",
      "   weighted avg       0.86      0.49      0.54       876\n",
      "\n",
      "\n",
      "IT Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.80      0.48      0.60       879\n",
      "    RECLAMATORY       0.18      0.48      0.26       207\n",
      "\n",
      "       accuracy                           0.48      1086\n",
      "      macro avg       0.49      0.48      0.43      1086\n",
      "   weighted avg       0.68      0.48      0.54      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = misclass_df\n",
    "    \n",
    "overall_metrics = calculate_overall_metrics(df, model_columns, model_names)\n",
    "\n",
    "language_metrics = calculate_language_wise_metrics(df, model_columns, model_names)\n",
    "\n",
    "print_results(overall_metrics, language_metrics)\n",
    "\n",
    "ranking = create_comparison_table(overall_metrics)\n",
    "\n",
    "best_model = ranking.iloc[0]['model']\n",
    "best_model_col = [k for k, v in model_names.items() if v == best_model][0]\n",
    "generate_detailed_report(df, best_model_col, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340afb8a-4990-4d0e-bfdc-3cd00d6fe88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipride",
   "language": "python",
   "name": "multipride"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
