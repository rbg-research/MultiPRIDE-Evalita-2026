{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df90f069-c8c2-45a8-a617-e37a6666e4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All random seeds set to 42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "from src.genai import GenAIClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d109807-412b-44d3-b092-5ab1641b9758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_en.csv', 'train_es.csv', 'train_it.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = \"../data/multipride_data/\"\n",
    "figures_root = \"../figures/\"\n",
    "results_root = \"../results/train/\"\n",
    "os.makedirs(figures_root, exist_ok=True)\n",
    "os.makedirs(results_root, exist_ok=True)\n",
    "\n",
    "train_files = [file for file in os.listdir(data_root) if (file.endswith(\".csv\") and (\"train\" in file))]\n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9da1255-234a-44bc-a40c-278c72b9f64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 2988\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame()\n",
    "\n",
    "for file in train_files:\n",
    "    temp_df = pd.read_csv(os.path.join(data_root, file))\n",
    "    if \"en\" in file:\n",
    "        temp_df[\"bio\"] = [None] * temp_df.shape[0]\n",
    "    train_df = pd.concat([train_df, temp_df], ignore_index=True)\n",
    "\n",
    "print(f\"Total training samples: {train_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4eb06ed-0c42-456b-97b0-68bbeb957588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lang</th>\n",
       "      <th>bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_1021</td>\n",
       "      <td>I've never heard anyone use the word \"faggot\" ...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_1496</td>\n",
       "      <td>So you don't see the slighest problem of someb...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en_1312</td>\n",
       "      <td>And to be fair, getting triggered by slurs is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en_469</td>\n",
       "      <td>I kinda feel like it's saying \"the faggot comm...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en_565</td>\n",
       "      <td>Homophobia, racism, and the resulting endless ...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  label lang  \\\n",
       "0  en_1021  I've never heard anyone use the word \"faggot\" ...      0   en   \n",
       "1  en_1496  So you don't see the slighest problem of someb...      0   en   \n",
       "2  en_1312  And to be fair, getting triggered by slurs is ...      1   en   \n",
       "3   en_469  I kinda feel like it's saying \"the faggot comm...      0   en   \n",
       "4   en_565  Homophobia, racism, and the resulting endless ...      0   en   \n",
       "\n",
       "    bio  \n",
       "0  None  \n",
       "1  None  \n",
       "2  None  \n",
       "3  None  \n",
       "4  None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d886933-4953-44dc-8451-950b783eb12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en', 'es', 'it'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_df.lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c620225-bd36-4d81-b7d5-d3168d4d0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_mapper = {\n",
    "    \"en\": \"English\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"it\": \"Italian\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720e1c01-5307-4793-a8f3-a331a91b15e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I\\'ve never heard anyone use the word \"faggot\" and not sound like an insecure 13 year old. ',\n",
       " 'en')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.text[0], train_df.lang[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c945492a-1ae3-4ab3-86c8-92482bf5606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "def calculate_overall_metrics(df, model_columns):\n",
    "    results = []\n",
    "    \n",
    "    for model_col in model_columns:\n",
    "        metrics = calculate_metrics(df['label'], df[model_col])\n",
    "        metrics['model'] = model_names.get(model_col, model_col)\n",
    "        metrics['n_samples'] = len(df)\n",
    "        results.append(metrics)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def calculate_language_wise_metrics(df, model_columns):\n",
    "    results = []\n",
    "    \n",
    "    languages = df['lang'].unique()\n",
    "    \n",
    "    for lang in sorted(languages):\n",
    "        df_lang = df[df['lang'] == lang]\n",
    "        \n",
    "        for model_col in model_columns:\n",
    "            metrics = calculate_metrics(df_lang['label'], df_lang[model_col])\n",
    "            metrics['model'] = model_names.get(model_col, model_col)\n",
    "            metrics['language'] = lang\n",
    "            metrics['n_samples'] = len(df_lang)\n",
    "            results.append(metrics)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def print_results(overall_df, language_df):\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"OVERALL METRICS (All Languages)\")\n",
    "    print(\"=\"*80)\n",
    "    print(overall_df.to_string(index=False))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"LANGUAGE-WISE METRICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    languages = language_df['language'].unique()\n",
    "    for lang in sorted(languages):\n",
    "        print(f\"\\n{lang.upper()} Language:\")\n",
    "        print(\"-\"*80)\n",
    "        lang_data = language_df[language_df['language'] == lang]\n",
    "        print(lang_data[['model', 'accuracy', 'precision', 'recall', 'f1', 'n_samples']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "def create_comparison_table(overall_df):\n",
    "    df_sorted = overall_df.sort_values('f1', ascending=False).reset_index(drop=True)\n",
    "    df_sorted['rank'] = range(1, len(df_sorted) + 1)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"MODEL RANKING (by F1-Score)\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_sorted[['rank', 'model', 'f1', 'accuracy', 'precision', 'recall', 'n_samples']].to_string(index=False))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return df_sorted\n",
    "\n",
    "def calculate_class_distribution(df):\n",
    "    print(\"=\"*80)\n",
    "    print(\"CLASS DISTRIBUTION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    overall_dist = df['label'].value_counts().sort_index()\n",
    "    print(f\"\\nOverall:\")\n",
    "    print(f\"  Class 0 (NOT_RECLAMATORY): {overall_dist.get(0, 0)} ({overall_dist.get(0, 0)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Class 1 (RECLAMATORY): {overall_dist.get(1, 0)} ({overall_dist.get(1, 0)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Total: {len(df)}\")\n",
    "    \n",
    "    print(f\"\\nPer Language:\")\n",
    "    for lang in sorted(df['lang'].unique()):\n",
    "        df_lang = df[df['lang'] == lang]\n",
    "        lang_dist = df_lang['label'].value_counts().sort_index()\n",
    "        print(f\"  {lang.upper()}: Class 0={lang_dist.get(0, 0)}, Class 1={lang_dist.get(1, 0)}, Total={len(df_lang)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "def generate_detailed_report(df, model_col):\n",
    "    model_name = model_names.get(model_col, model_col)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"DETAILED REPORT: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(\"\\nOverall Classification Report:\")\n",
    "    print(classification_report(df['label'], df[model_col], \n",
    "                                target_names=['NOT_RECLAMATORY', 'RECLAMATORY'],\n",
    "                                zero_division=0))\n",
    "    \n",
    "    cm = confusion_matrix(df['label'], df[model_col])\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(f\"                Predicted NOT    Predicted REC\")\n",
    "    print(f\"Actual NOT      {cm[0][0]:<15}  {cm[0][1]:<15}\")\n",
    "    print(f\"Actual REC      {cm[1][0]:<15}  {cm[1][1]:<15}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Per-Language Reports:\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for lang in sorted(df['lang'].unique()):\n",
    "        df_lang = df[df['lang'] == lang]\n",
    "        print(f\"\\n{lang.upper()} Language:\")\n",
    "        print(classification_report(df_lang['label'], df_lang[model_col],\n",
    "                                   target_names=['NOT_RECLAMATORY', 'RECLAMATORY'],\n",
    "                                   zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d718c79-24f5-4e2d-acd9-2cf0f4761830",
   "metadata": {},
   "source": [
    "# Vannila Prompt Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1bb119-a9e2-4e0e-8af1-5b20d35b0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai_classifier = GenAIClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03f98f9f-f262-48af-82be-27c9cc6e8b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze this tweet for LGBTQ+ reclamatory intent.\n",
      "            Strictly give final classification answer only, don't give any explanation.\n",
      "\n",
      "            RECLAMATORY = Pride, empowerment, self-affirmation\n",
      "            NOT_RECLAMATORY = Derogatory, neutral, or unclear\n",
      "            \n",
      "            Tweet (English): \"I've never heard anyone use the word \"faggot\" and not sound like an insecure 13 year old. \"\n",
      "            \n",
      "            Let's think step by step:\n",
      "            1. What term(s) are used?\n",
      "            2. Is the tone positive/affirmative?\n",
      "            3. Is it reclamatory?\n",
      "            \n",
      "            Answer:\n",
      "            Classification: [RECLAMATORY / NOT_RECLAMATORY]\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(genai_classifier.create_prompt(train_df.text[0], language_mapper[train_df.lang[0]], use_advanced=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b507d8a2-4990-4105-9690-5050306236e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vannila_df = pd.read_csv(\"../results/train/train_simple_prompt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6b61180-dbab-470c-a6f2-ee97847fd21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>label</th>\n",
       "      <th>HuggingFaceTB/SmolLM3-3B</th>\n",
       "      <th>microsoft/Phi-3.5-mini-instruct</th>\n",
       "      <th>tiiuae/Falcon3-3B-Instruct</th>\n",
       "      <th>Qwen/Qwen2.5-Omni-7B</th>\n",
       "      <th>google/gemma-3n-E4B-it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_1021</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_1496</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en_1312</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en_469</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en_565</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>it_1340</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>it_595</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>it_844</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>it_1216</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>it_521</td>\n",
       "      <td>it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2988 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id lang  label  HuggingFaceTB/SmolLM3-3B  \\\n",
       "0     en_1021   en      0                         0   \n",
       "1     en_1496   en      0                         0   \n",
       "2     en_1312   en      1                         1   \n",
       "3      en_469   en      0                         0   \n",
       "4      en_565   en      0                         1   \n",
       "...       ...  ...    ...                       ...   \n",
       "2983  it_1340   it      0                         0   \n",
       "2984   it_595   it      0                         0   \n",
       "2985   it_844   it      0                         0   \n",
       "2986  it_1216   it      0                         0   \n",
       "2987   it_521   it      1                         0   \n",
       "\n",
       "      microsoft/Phi-3.5-mini-instruct  tiiuae/Falcon3-3B-Instruct  \\\n",
       "0                                   0                           1   \n",
       "1                                   0                           1   \n",
       "2                                   1                           1   \n",
       "3                                   0                           1   \n",
       "4                                   1                           1   \n",
       "...                               ...                         ...   \n",
       "2983                                1                           1   \n",
       "2984                                1                           1   \n",
       "2985                                0                           1   \n",
       "2986                                1                           1   \n",
       "2987                                0                           1   \n",
       "\n",
       "      Qwen/Qwen2.5-Omni-7B  google/gemma-3n-E4B-it  \n",
       "0                        0                       0  \n",
       "1                        0                       1  \n",
       "2                        1                       1  \n",
       "3                        1                       0  \n",
       "4                        1                       1  \n",
       "...                    ...                     ...  \n",
       "2983                     0                       1  \n",
       "2984                     0                       0  \n",
       "2985                     0                       0  \n",
       "2986                     1                       1  \n",
       "2987                     0                       0  \n",
       "\n",
       "[2988 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vannila_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81684717-e2a2-4c8a-9586-54903e04b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns = [m for m in list(vannila_df.columns) if m not in [\"id\", \"lang\", \"label\"]]\n",
    "model_names = {}\n",
    "for model_column in model_columns:\n",
    "    model_names[model_column] = model_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10f793cf-7f81-4042-ad5d-8fbda2cd9df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLASS DISTRIBUTION\n",
      "================================================================================\n",
      "\n",
      "Overall:\n",
      "  Class 0 (NOT_RECLAMATORY): 2560 (85.7%)\n",
      "  Class 1 (RECLAMATORY): 428 (14.3%)\n",
      "  Total: 2988\n",
      "\n",
      "Per Language:\n",
      "  EN: Class 0=938, Class 1=88, Total=1026\n",
      "  ES: Class 0=743, Class 1=133, Total=876\n",
      "  IT: Class 0=879, Class 1=207, Total=1086\n",
      "\n",
      "\n",
      "================================================================================\n",
      "OVERALL METRICS (All Languages)\n",
      "================================================================================\n",
      " accuracy  precision   recall       f1                           model  n_samples\n",
      " 0.650602   0.188259 0.434579 0.262712        HuggingFaceTB/SmolLM3-3B       2988\n",
      " 0.491633   0.191634 0.792056 0.308603 microsoft/Phi-3.5-mini-instruct       2988\n",
      " 0.144578   0.143432 1.000000 0.250879      tiiuae/Falcon3-3B-Instruct       2988\n",
      " 0.506359   0.159844 0.574766 0.250127            Qwen/Qwen2.5-Omni-7B       2988\n",
      " 0.507363   0.178571 0.677570 0.282651          google/gemma-3n-E4B-it       2988\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LANGUAGE-WISE METRICS\n",
      "================================================================================\n",
      "\n",
      "EN Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                          model  accuracy  precision   recall       f1  n_samples\n",
      "       HuggingFaceTB/SmolLM3-3B  0.831384   0.236025 0.431818 0.305221       1026\n",
      "microsoft/Phi-3.5-mini-instruct  0.783626   0.213675 0.568182 0.310559       1026\n",
      "     tiiuae/Falcon3-3B-Instruct  0.089669   0.086106 1.000000 0.158559       1026\n",
      "           Qwen/Qwen2.5-Omni-7B  0.760234   0.144144 0.363636 0.206452       1026\n",
      "         google/gemma-3n-E4B-it  0.655945   0.152231 0.659091 0.247335       1026\n",
      "\n",
      "ES Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                          model  accuracy  precision   recall       f1  n_samples\n",
      "       HuggingFaceTB/SmolLM3-3B  0.489726   0.186000 0.699248 0.293839        876\n",
      "microsoft/Phi-3.5-mini-instruct  0.301370   0.175913 0.977444 0.298165        876\n",
      "     tiiuae/Falcon3-3B-Instruct  0.151826   0.151826 1.000000 0.263627        876\n",
      "           Qwen/Qwen2.5-Omni-7B  0.295662   0.172973 0.962406 0.293242        876\n",
      "         google/gemma-3n-E4B-it  0.386986   0.193009 0.954887 0.321113        876\n",
      "\n",
      "IT Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                          model  accuracy  precision   recall       f1  n_samples\n",
      "       HuggingFaceTB/SmolLM3-3B  0.609576   0.168196 0.265700 0.205993       1086\n",
      "microsoft/Phi-3.5-mini-instruct  0.369245   0.199749 0.768116 0.317049       1086\n",
      "     tiiuae/Falcon3-3B-Instruct  0.190608   0.190608 1.000000 0.320186       1086\n",
      "           Qwen/Qwen2.5-Omni-7B  0.436464   0.149047 0.415459 0.219388       1086\n",
      "         google/gemma-3n-E4B-it  0.464088   0.179487 0.507246 0.265152       1086\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MODEL RANKING (by F1-Score)\n",
      "================================================================================\n",
      " rank                           model       f1  accuracy  precision   recall  n_samples\n",
      "    1 microsoft/Phi-3.5-mini-instruct 0.308603  0.491633   0.191634 0.792056       2988\n",
      "    2          google/gemma-3n-E4B-it 0.282651  0.507363   0.178571 0.677570       2988\n",
      "    3        HuggingFaceTB/SmolLM3-3B 0.262712  0.650602   0.188259 0.434579       2988\n",
      "    4      tiiuae/Falcon3-3B-Instruct 0.250879  0.144578   0.143432 1.000000       2988\n",
      "    5            Qwen/Qwen2.5-Omni-7B 0.250127  0.506359   0.159844 0.574766       2988\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DETAILED REPORT: microsoft/Phi-3.5-mini-instruct\n",
      "================================================================================\n",
      "\n",
      "Overall Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.93      0.44      0.60      2560\n",
      "    RECLAMATORY       0.19      0.79      0.31       428\n",
      "\n",
      "       accuracy                           0.49      2988\n",
      "      macro avg       0.56      0.62      0.45      2988\n",
      "   weighted avg       0.82      0.49      0.56      2988\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted NOT    Predicted REC\n",
      "Actual NOT      1130             1430           \n",
      "Actual REC      89               339            \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Per-Language Reports:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "EN Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.95      0.80      0.87       938\n",
      "    RECLAMATORY       0.21      0.57      0.31        88\n",
      "\n",
      "       accuracy                           0.78      1026\n",
      "      macro avg       0.58      0.69      0.59      1026\n",
      "   weighted avg       0.89      0.78      0.82      1026\n",
      "\n",
      "\n",
      "ES Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.98      0.18      0.30       743\n",
      "    RECLAMATORY       0.18      0.98      0.30       133\n",
      "\n",
      "       accuracy                           0.30       876\n",
      "      macro avg       0.58      0.58      0.30       876\n",
      "   weighted avg       0.86      0.30      0.30       876\n",
      "\n",
      "\n",
      "IT Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.83      0.28      0.41       879\n",
      "    RECLAMATORY       0.20      0.77      0.32       207\n",
      "\n",
      "       accuracy                           0.37      1086\n",
      "      macro avg       0.52      0.52      0.37      1086\n",
      "   weighted avg       0.71      0.37      0.40      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = vannila_df\n",
    "\n",
    "calculate_class_distribution(df)\n",
    "    \n",
    "overall_metrics = calculate_overall_metrics(df, model_columns)\n",
    "\n",
    "language_metrics = calculate_language_wise_metrics(df, model_columns)\n",
    "\n",
    "print_results(overall_metrics, language_metrics)\n",
    "\n",
    "ranking = create_comparison_table(overall_metrics)\n",
    "\n",
    "best_model = ranking.iloc[0]['model']\n",
    "best_model_col = [k for k, v in model_names.items() if v == best_model][0]\n",
    "generate_detailed_report(df, best_model_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c160e1c-2095-4d35-87e8-b27ba0b130c9",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompt Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe3de017-6521-453a-bcd7-d662c9a997ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_df = pd.read_csv(\"../results/train/train_cot_prompt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "660c4ae9-56dc-4c9b-b3ad-839ef9d813ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>label</th>\n",
       "      <th>HuggingFaceTB/SmolLM3-3B</th>\n",
       "      <th>microsoft/Phi-3.5-mini-instruct</th>\n",
       "      <th>tiiuae/Falcon3-3B-Instruct</th>\n",
       "      <th>Qwen/Qwen2.5-Omni-7B</th>\n",
       "      <th>google/gemma-3n-E4B-it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_1021</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_1496</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en_1312</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en_469</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en_565</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>it_1340</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>it_595</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>it_844</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>it_1216</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>it_521</td>\n",
       "      <td>it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2988 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id lang  label  HuggingFaceTB/SmolLM3-3B  \\\n",
       "0     en_1021   en      0                         0   \n",
       "1     en_1496   en      0                         0   \n",
       "2     en_1312   en      1                         1   \n",
       "3      en_469   en      0                         0   \n",
       "4      en_565   en      0                         0   \n",
       "...       ...  ...    ...                       ...   \n",
       "2983  it_1340   it      0                         0   \n",
       "2984   it_595   it      0                         0   \n",
       "2985   it_844   it      0                         0   \n",
       "2986  it_1216   it      0                         1   \n",
       "2987   it_521   it      1                         0   \n",
       "\n",
       "      microsoft/Phi-3.5-mini-instruct  tiiuae/Falcon3-3B-Instruct  \\\n",
       "0                                   0                           1   \n",
       "1                                   0                           1   \n",
       "2                                   1                           0   \n",
       "3                                   0                           1   \n",
       "4                                   1                           1   \n",
       "...                               ...                         ...   \n",
       "2983                                0                           1   \n",
       "2984                                1                           1   \n",
       "2985                                0                           1   \n",
       "2986                                1                           1   \n",
       "2987                                0                           1   \n",
       "\n",
       "      Qwen/Qwen2.5-Omni-7B  google/gemma-3n-E4B-it  \n",
       "0                        0                       0  \n",
       "1                        0                       0  \n",
       "2                        1                       1  \n",
       "3                        1                       0  \n",
       "4                        1                       0  \n",
       "...                    ...                     ...  \n",
       "2983                     0                       1  \n",
       "2984                     0                       0  \n",
       "2985                     0                       0  \n",
       "2986                     1                       1  \n",
       "2987                     0                       0  \n",
       "\n",
       "[2988 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a0b43cd-f04e-4282-a82f-2725f2398146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns = [m for m in list(cot_df.columns) if m not in [\"id\", \"lang\", \"label\"]]\n",
    "model_columns = model_names\n",
    "model_names = {}\n",
    "for model_column in model_columns:\n",
    "    model_names[model_column] = model_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d216687f-f34c-46e4-bebf-8a752480953d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OVERALL METRICS (All Languages)\n",
      "================================================================================\n",
      " accuracy  precision   recall       f1                           model  n_samples\n",
      " 0.647256   0.205273 0.509346 0.292617        HuggingFaceTB/SmolLM3-3B       2988\n",
      " 0.556560   0.197164 0.682243 0.305919 microsoft/Phi-3.5-mini-instruct       2988\n",
      " 0.280120   0.159082 0.939252 0.272081      tiiuae/Falcon3-3B-Instruct       2988\n",
      " 0.548193   0.164483 0.528037 0.250832            Qwen/Qwen2.5-Omni-7B       2988\n",
      " 0.561580   0.164384 0.504673 0.247991          google/gemma-3n-E4B-it       2988\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LANGUAGE-WISE METRICS\n",
      "================================================================================\n",
      "\n",
      "EN Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                          model  accuracy  precision   recall       f1  n_samples\n",
      "       HuggingFaceTB/SmolLM3-3B  0.825536   0.242938 0.488636 0.324528       1026\n",
      "microsoft/Phi-3.5-mini-instruct  0.823587   0.251337 0.534091 0.341818       1026\n",
      "     tiiuae/Falcon3-3B-Instruct  0.451267   0.107438 0.738636 0.187590       1026\n",
      "           Qwen/Qwen2.5-Omni-7B  0.777778   0.178899 0.443182 0.254902       1026\n",
      "         google/gemma-3n-E4B-it  0.753411   0.171315 0.488636 0.253687       1026\n",
      "\n",
      "ES Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                          model  accuracy  precision   recall       f1  n_samples\n",
      "       HuggingFaceTB/SmolLM3-3B  0.501142   0.205426 0.796992 0.326656        876\n",
      "microsoft/Phi-3.5-mini-instruct  0.342466   0.181295 0.947368 0.304348        876\n",
      "     tiiuae/Falcon3-3B-Instruct  0.163242   0.152778 0.992481 0.264794        876\n",
      "           Qwen/Qwen2.5-Omni-7B  0.340183   0.173275 0.887218 0.289926        876\n",
      "         google/gemma-3n-E4B-it  0.422374   0.174520 0.751880 0.283286        876\n",
      "\n",
      "IT Language:\n",
      "--------------------------------------------------------------------------------\n",
      "                          model  accuracy  precision   recall       f1  n_samples\n",
      "       HuggingFaceTB/SmolLM3-3B  0.596685   0.186992 0.333333 0.239583       1086\n",
      "microsoft/Phi-3.5-mini-instruct  0.476980   0.198664 0.574879 0.295285       1086\n",
      "     tiiuae/Falcon3-3B-Instruct  0.212707   0.193762 0.990338 0.324111       1086\n",
      "           Qwen/Qwen2.5-Omni-7B  0.499079   0.145263 0.333333 0.202346       1086\n",
      "         google/gemma-3n-E4B-it  0.492634   0.148980 0.352657 0.209469       1086\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MODEL RANKING (by F1-Score)\n",
      "================================================================================\n",
      " rank                           model       f1  accuracy  precision   recall  n_samples\n",
      "    1 microsoft/Phi-3.5-mini-instruct 0.305919  0.556560   0.197164 0.682243       2988\n",
      "    2        HuggingFaceTB/SmolLM3-3B 0.292617  0.647256   0.205273 0.509346       2988\n",
      "    3      tiiuae/Falcon3-3B-Instruct 0.272081  0.280120   0.159082 0.939252       2988\n",
      "    4            Qwen/Qwen2.5-Omni-7B 0.250832  0.548193   0.164483 0.528037       2988\n",
      "    5          google/gemma-3n-E4B-it 0.247991  0.561580   0.164384 0.504673       2988\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DETAILED REPORT: microsoft/Phi-3.5-mini-instruct\n",
      "================================================================================\n",
      "\n",
      "Overall Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.91      0.54      0.67      2560\n",
      "    RECLAMATORY       0.20      0.68      0.31       428\n",
      "\n",
      "       accuracy                           0.56      2988\n",
      "      macro avg       0.55      0.61      0.49      2988\n",
      "   weighted avg       0.81      0.56      0.62      2988\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted NOT    Predicted REC\n",
      "Actual NOT      1371             1189           \n",
      "Actual REC      136              292            \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Per-Language Reports:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "EN Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.95      0.85      0.90       938\n",
      "    RECLAMATORY       0.25      0.53      0.34        88\n",
      "\n",
      "       accuracy                           0.82      1026\n",
      "      macro avg       0.60      0.69      0.62      1026\n",
      "   weighted avg       0.89      0.82      0.85      1026\n",
      "\n",
      "\n",
      "ES Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.96      0.23      0.38       743\n",
      "    RECLAMATORY       0.18      0.95      0.30       133\n",
      "\n",
      "       accuracy                           0.34       876\n",
      "      macro avg       0.57      0.59      0.34       876\n",
      "   weighted avg       0.84      0.34      0.37       876\n",
      "\n",
      "\n",
      "IT Language:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_RECLAMATORY       0.82      0.45      0.58       879\n",
      "    RECLAMATORY       0.20      0.57      0.30       207\n",
      "\n",
      "       accuracy                           0.48      1086\n",
      "      macro avg       0.51      0.51      0.44      1086\n",
      "   weighted avg       0.70      0.48      0.53      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = cot_df\n",
    "    \n",
    "overall_metrics = calculate_overall_metrics(df, model_columns)\n",
    "\n",
    "language_metrics = calculate_language_wise_metrics(df, model_columns)\n",
    "\n",
    "print_results(overall_metrics, language_metrics)\n",
    "\n",
    "ranking = create_comparison_table(overall_metrics)\n",
    "\n",
    "best_model = ranking.iloc[0]['model']\n",
    "best_model_col = [k for k, v in model_names.items() if v == best_model][0]\n",
    "generate_detailed_report(df, best_model_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360718fd-b22b-4220-801b-c6bf5c332d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipride",
   "language": "python",
   "name": "multipride"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
